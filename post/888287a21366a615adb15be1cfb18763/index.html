<!doctype html><html lang=zh-cn><head><meta charset=utf-8><title>政府究竟该如何监管人工智能</title><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content=" 政府究竟该如何监管人工智能
作者：吴修铭　2023年11月7日纽约时报
上周，在签署关于人工智能的全面行政命令时，拜登总统开玩笑说，看到“深度伪造”的自己是一种奇怪的体验，“我到底什么时候说过那种话？”
他的调侃意味深长，将这项行政命令与一种人人都能理解的人工智能危害联系了起来，那就是冒充他人。另一个案例是近来泛滥的虚拟裸照，已经毁掉了许多高中女孩的生活。这些已成为日常的事件都指向一个重要的事实，那就是监管人工智能的努力是否成功，将决定政府能否专注于解决诸如深度伪造的切实问题，而不是被机器主宰人类等臆想危险所淹没。
拜登的行政命令甚至超出了欧洲政府的监管范畴，从无处不在的诈骗到大规模杀伤性武器的研发，涵盖了人们能想到的几乎所有潜在风险。该命令将为人工智能安全和可信度设下标准，打造一项开发人工智能工具的网络安全计划，并要求开发可能对国家安全构成威胁的人工智能系统的企业向联邦政府分享安全测试结果。
白宫在人工智能问题上如此大力投入是正确的决定，为的是避免重蹈2010年代在有效监管社交媒体问题上的灾难性覆辙。因为政府的袖手旁观，社交媒体技术从看似人畜无害的私人朋友圈更新工具演变为大规模心理操纵的手段，加之侵犯隐私的商业模式和伤害青少年、助长错误信息并推动洗脑灌输传播的黑历史，堪称五毒俱全。
但如果说社交网络是披着羊皮的狼，那人工智能这头“狼”更像是披上了末日骑士的外衣。大众的想象总将人工智能与斯坦利·库布里克的电影《2001太空漫游》(2001: A Space Odyssey)中发生邪恶故障的“哈尔”(HAL 9000)，以及《终结者》(Terminator)系列中拥有自我意识的大反派“天网”(Skynet)联系到一起。不过，虽然人工智能带来的问题和挑战确实需要政府采取行动，但对末日到来的担忧——无论是自动化带来的大规模失业还是以灭绝人类为使命的超智慧人工智能——仍然只是猜测。
如果说政府对社交媒体作为太少且太迟是个错误，那我们如今需要警惕的是过早采取政府行动，导致实际危害难以得到解决。
忍不住想拿出过度反应是可以理解的。谁也不想成为灾难电影里那些无知的官员，对即将到来的灾变的早期征兆不屑一顾。白宫想对人工智能进行标准化测试并对灾难性风险进行独立监督没有错。拜登的行政命令要求研发最强大人工智能系统的企业向政府通报安全测试情况，并要劳工部长研究人工智能取代人类岗位的风险和补救措施。
但事实是，没人知道这些惊天动地的发展是否能够实现。科技的预言与气候科学不同，其参数是相对有限的。从每周30小时和15小时的工作时间到电视的消亡，科技的历史中充斥着始终没有发生的自信预期和“必然”。以沉重口吻论述令人恐惧的可能性确实能吸引眼球。但这也是世界为应对“千年虫”而浪费数以千亿计美元的原因。
监管充满变数的风险而非实际危害的做法并不明智，原因有二。首先，过于急切的监管者可能会目光短浅地锁定错误的监管对象。例如，为了应对数字盗版风险，国会曾于1992年对数码录音带进行广泛监管，但随着互联网和MP3的崛起，如今只有发烧友才会记得这种录音媒介。无独有偶，今天的政策制定者都在关注ChatGPT这样的大语言模型，它们是可能塑造未来——但考虑到其根植于持续伪造和扭曲的整体不可靠性，它们最终可能只会成为人工智能时代的呼啦圈。
其次，先制性监管会给有意突入某一产业的公司制造障碍。有实力的企业可以在律师和专家上花费数百万美元，想方设法适应一套复杂的新监管规则，然而规模较小的初创公司通常没有这样的资源。这就会滋养垄断，抑制创新。科技产业已经过多地被掌握在几家大公司手里。对人工智能进行最严格的监管会导致只有谷歌、微软、苹果以及它们的主要合作伙伴能在该领域竞争。最积极的AI严格监管倡导者正是这些公司和合作伙伴，这不是巧合。
相比空想出来的风险，以实际危害来引导政府在何时以何种方式介入，是好得多的标准。人工智能目前最明显的危害在于人类模仿（例如假冒的裸照）、歧视和年轻人成瘾。2020年，窃贼使用冒充的人声从一家在香港的日本企业那里骗走了3500万美元。面部识别技术导致了错误的逮捕和监禁，比如尼杰尔·帕克斯案，由于身份识别错误，他在新泽西州一家拘留所被关了10天。假冒的顾客评价损害了消费者信心，假社媒账号在推动政治宣传。由AI驱动的算法被用于增强本已经具有成瘾性的社交媒体属性。
这些例子听上去不像人工智能安全中心今年发布的警告那么惊悚，报告称“降低因人工智能导致灭绝的风险，应该是与传染病大流行和核战争等社会规模风险一样的全球优先事项”。但是这些不那么耸动的例子，偏偏是存在真实的受害者的。
值得肯定的是，拜登的行政令并没有完全受制于这样的假说：它的主要内容是为将来的行动给出一个框架。命令中的某些建议是紧迫而重要的，例如建立人工智能生成照片、视频、音频和文字水印标记的标准。
但是，行政部门的力量当然是有限的。国会应该仿效行政部门，对那些假设性问题保持关注，同时采取有力的行动，让我们免受人类模仿、算法操控、不实信息和其他紧迫的人工智能问题的危害——当然还要通过网络隐私和儿童保护法律，这些法案已在国会进行反复听证，有民众的支持，却始终未能颁布。
监管并不像你在程式化的政治辩论中所听到的那样，与这个或那个政党的利益保持着一致。它只是在行使政府权力，这可能是好事也可能是坏事，可能是在保护弱势者，也可能是加强已有的权力。着眼于未知未来的人工智能监管可能会被用于协助权力者确保垄断地位，拖累那些致力于用计算技术改善人类状况的人。如果能以正确的方式着眼于当下，它也许能保护弱势者，促进更广泛、更有益的创新。
具体社会危害的存在一直都是政府行为是否合理的试金石。但这是把双刃剑：政府在没有危害时应该保持警惕，并在发现危害时有责任采取行动。从这个角度讲，在人工智能的问题上，我们可能在做得过分的同时也做得不够。
吴修铭是哥伦比亚大学法学教授，著有《The Curse of Bigness: Antitrust in the New Gilded Age》一书。
翻译：纽约时报中文网
(XYS20231107) "><meta name=generator content="Hugo 0.100.2"><link rel=stylesheet href=../../plugins/bootstrap/bootstrap.min.css><link rel=stylesheet href=../../plugins/themify-icons/themify-icons.css><link rel=stylesheet href=https://project-gutenberg.github.io/Pincong/scss/style.min.css media=screen><link rel="shortcut icon" href=https://project-gutenberg.github.io/Pincong/images/favicon.png type=image/x-icon><link rel=icon href=https://project-gutenberg.github.io/Pincong/images/favicon.png type=image/x-icon><meta name=twitter:card content="summary_large_image"><meta name=og:title content=" 政府究竟该如何监管人工智能 "><meta name=og:description content=" 政府究竟该如何监管人工智能
作者：吴修铭　2023年11月7日纽约时报
上周，在签署关于人工智能的全面行政命令时，拜登总统开玩笑说，看到“深度伪造”的自己是一种奇怪的体验，“我到底什么时候说过那种话？”
他的调侃意味深长，将这项行政命令与一种人人都能理解的人工智能危害联系了起来，那就是冒充他人。另一个案例是近来泛滥的虚拟裸照，已经毁掉了许多高中女孩的生活。这些已成为日常的事件都指向一个重要的事实，那就是监管人工智能的努力是否成功，将决定政府能否专注于解决诸如深度伪造的切实问题，而不是被机器主宰人类等臆想危险所淹没。
拜登的行政命令甚至超出了欧洲政府的监管范畴，从无处不在的诈骗到大规模杀伤性武器的研发，涵盖了人们能想到的几乎所有潜在风险。该命令将为人工智能安全和可信度设下标准，打造一项开发人工智能工具的网络安全计划，并要求开发可能对国家安全构成威胁的人工智能系统的企业向联邦政府分享安全测试结果。
白宫在人工智能问题上如此大力投入是正确的决定，为的是避免重蹈2010年代在有效监管社交媒体问题上的灾难性覆辙。因为政府的袖手旁观，社交媒体技术从看似人畜无害的私人朋友圈更新工具演变为大规模心理操纵的手段，加之侵犯隐私的商业模式和伤害青少年、助长错误信息并推动洗脑灌输传播的黑历史，堪称五毒俱全。
但如果说社交网络是披着羊皮的狼，那人工智能这头“狼”更像是披上了末日骑士的外衣。大众的想象总将人工智能与斯坦利·库布里克的电影《2001太空漫游》(2001: A Space Odyssey)中发生邪恶故障的“哈尔”(HAL 9000)，以及《终结者》(Terminator)系列中拥有自我意识的大反派“天网”(Skynet)联系到一起。不过，虽然人工智能带来的问题和挑战确实需要政府采取行动，但对末日到来的担忧——无论是自动化带来的大规模失业还是以灭绝人类为使命的超智慧人工智能——仍然只是猜测。
如果说政府对社交媒体作为太少且太迟是个错误，那我们如今需要警惕的是过早采取政府行动，导致实际危害难以得到解决。
忍不住想拿出过度反应是可以理解的。谁也不想成为灾难电影里那些无知的官员，对即将到来的灾变的早期征兆不屑一顾。白宫想对人工智能进行标准化测试并对灾难性风险进行独立监督没有错。拜登的行政命令要求研发最强大人工智能系统的企业向政府通报安全测试情况，并要劳工部长研究人工智能取代人类岗位的风险和补救措施。
但事实是，没人知道这些惊天动地的发展是否能够实现。科技的预言与气候科学不同，其参数是相对有限的。从每周30小时和15小时的工作时间到电视的消亡，科技的历史中充斥着始终没有发生的自信预期和“必然”。以沉重口吻论述令人恐惧的可能性确实能吸引眼球。但这也是世界为应对“千年虫”而浪费数以千亿计美元的原因。
监管充满变数的风险而非实际危害的做法并不明智，原因有二。首先，过于急切的监管者可能会目光短浅地锁定错误的监管对象。例如，为了应对数字盗版风险，国会曾于1992年对数码录音带进行广泛监管，但随着互联网和MP3的崛起，如今只有发烧友才会记得这种录音媒介。无独有偶，今天的政策制定者都在关注ChatGPT这样的大语言模型，它们是可能塑造未来——但考虑到其根植于持续伪造和扭曲的整体不可靠性，它们最终可能只会成为人工智能时代的呼啦圈。
其次，先制性监管会给有意突入某一产业的公司制造障碍。有实力的企业可以在律师和专家上花费数百万美元，想方设法适应一套复杂的新监管规则，然而规模较小的初创公司通常没有这样的资源。这就会滋养垄断，抑制创新。科技产业已经过多地被掌握在几家大公司手里。对人工智能进行最严格的监管会导致只有谷歌、微软、苹果以及它们的主要合作伙伴能在该领域竞争。最积极的AI严格监管倡导者正是这些公司和合作伙伴，这不是巧合。
相比空想出来的风险，以实际危害来引导政府在何时以何种方式介入，是好得多的标准。人工智能目前最明显的危害在于人类模仿（例如假冒的裸照）、歧视和年轻人成瘾。2020年，窃贼使用冒充的人声从一家在香港的日本企业那里骗走了3500万美元。面部识别技术导致了错误的逮捕和监禁，比如尼杰尔·帕克斯案，由于身份识别错误，他在新泽西州一家拘留所被关了10天。假冒的顾客评价损害了消费者信心，假社媒账号在推动政治宣传。由AI驱动的算法被用于增强本已经具有成瘾性的社交媒体属性。
这些例子听上去不像人工智能安全中心今年发布的警告那么惊悚，报告称“降低因人工智能导致灭绝的风险，应该是与传染病大流行和核战争等社会规模风险一样的全球优先事项”。但是这些不那么耸动的例子，偏偏是存在真实的受害者的。
值得肯定的是，拜登的行政令并没有完全受制于这样的假说：它的主要内容是为将来的行动给出一个框架。命令中的某些建议是紧迫而重要的，例如建立人工智能生成照片、视频、音频和文字水印标记的标准。
但是，行政部门的力量当然是有限的。国会应该仿效行政部门，对那些假设性问题保持关注，同时采取有力的行动，让我们免受人类模仿、算法操控、不实信息和其他紧迫的人工智能问题的危害——当然还要通过网络隐私和儿童保护法律，这些法案已在国会进行反复听证，有民众的支持，却始终未能颁布。
监管并不像你在程式化的政治辩论中所听到的那样，与这个或那个政党的利益保持着一致。它只是在行使政府权力，这可能是好事也可能是坏事，可能是在保护弱势者，也可能是加强已有的权力。着眼于未知未来的人工智能监管可能会被用于协助权力者确保垄断地位，拖累那些致力于用计算技术改善人类状况的人。如果能以正确的方式着眼于当下，它也许能保护弱势者，促进更广泛、更有益的创新。
具体社会危害的存在一直都是政府行为是否合理的试金石。但这是把双刃剑：政府在没有危害时应该保持警惕，并在发现危害时有责任采取行动。从这个角度讲，在人工智能的问题上，我们可能在做得过分的同时也做得不够。
吴修铭是哥伦比亚大学法学教授，著有《The Curse of Bigness: Antitrust in the New Gilded Age》一书。
翻译：纽约时报中文网
(XYS20231107) "><meta name=og:image content="https://project-gutenberg.github.io/Pincong//images/card/34.jpg"><script data-ad-client=ca-pub-6074407261372769 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-06HJ1E5XNH"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-06HJ1E5XNH')</script></head><body><header class="fixed-top navigation"><div class=container><nav class="navbar navbar-expand-lg navbar-light bg-transparent"><a class=navbar-brand href=https://project-gutenberg.github.io/Pincong/><img class=img-fluid src=https://project-gutenberg.github.io/Pincong//images/logo.png alt=品葱*精选></a>
<button class="navbar-toggler border-0" type=button data-toggle=collapse data-target=#navigation>
<i class="ti-menu h3"></i></button><div class="collapse navbar-collapse text-center" id=navigation><ul class="navbar-nav ml-auto"><li class=nav-item><a class=nav-link href=https://project-gutenberg.github.io/Pincong/>Home</a></li><li class=nav-item><a class=nav-link href=https://project-gutenberg.github.io/Pincong/post/index.xml>RSS</a></li><li class=nav-item><a class=nav-link href=https://bit.ly/2HrxEi0>Telegram</a></li><li class=nav-item><a class=nav-link href=https://twitter.com/speechfree3>Twitter</a></li></ul></div></nav></div></header><div class="py-5 d-none d-lg-block"></div><section class=main-content><div class=container><div class=row><div class="col-lg-8 mx-auto block shadow mb-5"><h2>政府究竟该如何监管人工智能</h2><div class=mb-3><span>by <a href=https://project-gutenberg.github.io/Pincong/author/%e5%90%b4%e4%bf%ae%e9%93%ad-2023%e5%b9%b411%e6%9c%887%e6%97%a5%e7%ba%bd%e7%ba%a6%e6%97%b6%e6%8a%a5>吴修铭 2023年11月7日纽约时报</a></span>,
<span>at 18 November 2023</span>, tags :
<a href=https://project-gutenberg.github.io/Pincong/tags/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd>人工智能</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e7%9b%91%e7%ae%a1>监管</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e5%8d%b1%e5%ae%b3>危害</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e6%94%bf%e5%ba%9c>政府</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e6%8b%9c%e7%99%bb>拜登</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e6%96%b0%e8%af%ad%e4%b8%9d>新语丝</a>
<a href=https://github.com/Project-Gutenberg/Pincong-data/edit/master/site/content/post/888287a21366a615adb15be1cfb18763.md style=color:gray><strong><i>点击纠错</i></strong></a>
<i></i><a href=https://github.com/Project-Gutenberg/Pincong-data/delete/master/site/content/post/888287a21366a615adb15be1cfb18763.md style=color:gray><strong><i>点击删除</i></strong></a></div><h5><a href=https://bit.ly/justmysock>使用CN2/CN2GIA顶级线路，支持Shadowsocks/V2ray科学上网，支持支付宝付款，每月仅需 5 美元</a></h5><h5><a href=https://bit.ly/2HrxEi0>## 加入品葱精选 Telegram Channel ##</a></h5><p></p><p>政府究竟该如何监管人工智能</p><p>作者：吴修铭　　2023年11月7日纽约时报</p><p>上周，在签署关于人工智能的全面行政命令时，拜登总统开玩笑说，看到“深度伪造”的自己是一种奇怪的体验，“我到底什么时候说过那种话？”</p><p>他的调侃意味深长，将这项行政命令与一种人人都能理解的人工智能危害联系了起来，那就是冒充他人。另一个案例是近来泛滥的虚拟裸照，已经毁掉了许多高中女孩的生活。这些已成为日常的事件都指向一个重要的事实，那就是监管人工智能的努力是否成功，将决定政府能否专注于解决诸如深度伪造的切实问题，而不是被机器主宰人类等臆想危险所淹没。</p><p>拜登的行政命令甚至超出了欧洲政府的监管范畴，从无处不在的诈骗到大规模杀伤性武器的研发，涵盖了人们能想到的几乎所有潜在风险。该命令将为人工智能安全和可信度设下标准，打造一项开发人工智能工具的网络安全计划，并要求开发可能对国家安全构成威胁的人工智能系统的企业向联邦政府分享安全测试结果。</p><p>白宫在人工智能问题上如此大力投入是正确的决定，为的是避免重蹈2010年代在有效监管社交媒体问题上的灾难性覆辙。因为政府的袖手旁观，社交媒体技术从看似人畜无害的私人朋友圈更新工具演变为大规模心理操纵的手段，加之侵犯隐私的商业模式和伤害青少年、助长错误信息并推动洗脑灌输传播的黑历史，堪称五毒俱全。</p><p>但如果说社交网络是披着羊皮的狼，那人工智能这头“狼”更像是披上了末日骑士的外衣。大众的想象总将人工智能与斯坦利·库布里克的电影《2001太空漫游》(2001: A Space Odyssey)中发生邪恶故障的“哈尔”(HAL 9000)，以及《终结者》(Terminator)系列中拥有自我意识的大反派“天网”(Skynet)联系到一起。不过，虽然人工智能带来的问题和挑战确实需要政府采取行动，但对末日到来的担忧——无论是自动化带来的大规模失业还是以灭绝人类为使命的超智慧人工智能——仍然只是猜测。</p><p>如果说政府对社交媒体作为太少且太迟是个错误，那我们如今需要警惕的是过早采取政府行动，导致实际危害难以得到解决。</p><p>忍不住想拿出过度反应是可以理解的。谁也不想成为灾难电影里那些无知的官员，对即将到来的灾变的早期征兆不屑一顾。白宫想对人工智能进行标准化测试并对灾难性风险进行独立监督没有错。拜登的行政命令要求研发最强大人工智能系统的企业向政府通报安全测试情况，并要劳工部长研究人工智能取代人类岗位的风险和补救措施。</p><p>但事实是，没人知道这些惊天动地的发展是否能够实现。科技的预言与气候科学不同，其参数是相对有限的。从每周30小时和15小时的工作时间到电视的消亡，科技的历史中充斥着始终没有发生的自信预期和“必然”。以沉重口吻论述令人恐惧的可能性确实能吸引眼球。但这也是世界为应对“千年虫”而浪费数以千亿计美元的原因。</p><p>监管充满变数的风险而非实际危害的做法并不明智，原因有二。首先，过于急切的监管者可能会目光短浅地锁定错误的监管对象。例如，为了应对数字盗版风险，国会曾于1992年对数码录音带进行广泛监管，但随着互联网和MP3的崛起，如今只有发烧友才会记得这种录音媒介。无独有偶，今天的政策制定者都在关注ChatGPT这样的大语言模型，它们是可能塑造未来——但考虑到其根植于持续伪造和扭曲的整体不可靠性，它们最终可能只会成为人工智能时代的呼啦圈。</p><p>其次，先制性监管会给有意突入某一产业的公司制造障碍。有实力的企业可以在律师和专家上花费数百万美元，想方设法适应一套复杂的新监管规则，然而规模较小的初创公司通常没有这样的资源。这就会滋养垄断，抑制创新。科技产业已经过多地被掌握在几家大公司手里。对人工智能进行最严格的监管会导致只有谷歌、微软、苹果以及它们的主要合作伙伴能在该领域竞争。最积极的AI严格监管倡导者正是这些公司和合作伙伴，这不是巧合。</p><p>相比空想出来的风险，以实际危害来引导政府在何时以何种方式介入，是好得多的标准。人工智能目前最明显的危害在于人类模仿（例如假冒的裸照）、歧视和年轻人成瘾。2020年，窃贼使用冒充的人声从一家在香港的日本企业那里骗走了3500万美元。面部识别技术导致了错误的逮捕和监禁，比如尼杰尔·帕克斯案，由于身份识别错误，他在新泽西州一家拘留所被关了10天。假冒的顾客评价损害了消费者信心，假社媒账号在推动政治宣传。由AI驱动的算法被用于增强本已经具有成瘾性的社交媒体属性。</p><p>这些例子听上去不像人工智能安全中心今年发布的警告那么惊悚，报告称“降低因人工智能导致灭绝的风险，应该是与传染病大流行和核战争等社会规模风险一样的全球优先事项”。但是这些不那么耸动的例子，偏偏是存在真实的受害者的。</p><p>值得肯定的是，拜登的行政令并没有完全受制于这样的假说：它的主要内容是为将来的行动给出一个框架。命令中的某些建议是紧迫而重要的，例如建立人工智能生成照片、视频、音频和文字水印标记的标准。</p><p>但是，行政部门的力量当然是有限的。国会应该仿效行政部门，对那些假设性问题保持关注，同时采取有力的行动，让我们免受人类模仿、算法操控、不实信息和其他紧迫的人工智能问题的危害——当然还要通过网络隐私和儿童保护法律，这些法案已在国会进行反复听证，有民众的支持，却始终未能颁布。</p><p>监管并不像你在程式化的政治辩论中所听到的那样，与这个或那个政党的利益保持着一致。它只是在行使政府权力，这可能是好事也可能是坏事，可能是在保护弱势者，也可能是加强已有的权力。着眼于未知未来的人工智能监管可能会被用于协助权力者确保垄断地位，拖累那些致力于用计算技术改善人类状况的人。如果能以正确的方式着眼于当下，它也许能保护弱势者，促进更广泛、更有益的创新。</p><p>具体社会危害的存在一直都是政府行为是否合理的试金石。但这是把双刃剑：政府在没有危害时应该保持警惕，并在发现危害时有责任采取行动。从这个角度讲，在人工智能的问题上，我们可能在做得过分的同时也做得不够。</p><p>吴修铭是哥伦比亚大学法学教授，著有《The Curse of Bigness: Antitrust in the New Gilded Age》一书。</p><p>翻译：纽约时报中文网</p><p>(XYS20231107)</p><h5><a href="https://www.digitalocean.com/?refcode=4351d40e44b2&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=CopyPaste">最简单好用的 VPS,没有之一，注册立得 100 美金</a></h5></div><div class="col-lg-8 mx-auto block shadow"><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var t=document,e=t.createElement('script');e.async=!0,e.src='//pin-cong-jing-xuan.disqus.com/embed.js',e.setAttribute('data-timestamp',+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><div class="col-lg-8 mx-auto block shadow"><h3>See Also</h3><div class=container><div class=row><div class="mx-auto px-0"><div class="bg-white shadow block"><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/cbe7a0c6f231be95eafc3f192e9776a2/?utm_source=see_also&utm_medium=%25E6%2594%25BF%25E5%25BA%259C%25E7%25A9%25B6%25E7%25AB%259F%25E8%25AF%25A5%25E5%25A6%2582%25E4%25BD%2595%25E7%259B%2591%25E7%25AE%25A1%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BD">习近平是不是独裁者？</a></h2><p class=text-dark>习近平是不是独裁者？
·方舟子·
最近拜登总统到加州访问，为竞选总统募集捐款，向捐款者发表演讲。在演讲中，他提到了中国流浪气球事件。我以前谈到过，美国军方认为中国气球是流浪到美国本土的，原计划飞到美国夏威夷、关岛的军事基地进行侦察，以前就是 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/a37b1b7fb1c98a6a06cf6ed801bb45ae/?utm_source=see_also&utm_medium=%25E6%2594%25BF%25E5%25BA%259C%25E7%25A9%25B6%25E7%25AB%259F%25E8%25AF%25A5%25E5%25A6%2582%25E4%25BD%2595%25E7%259B%2591%25E7%25AE%25A1%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BD">从司马南散布美国谣言说说反美斗士</a></h2><p class=text-dark>从司马南散布美国谣言说说反美斗士
·方舟子·
川普嚷嚷说，纽约的检察官马上就要逮捕他了，要他的支持者出来示威抗议，但响应他的号召出来示威抗议的没几个人。这事在中国引起了很大的反响。司马南评论说，这是一个上台的老头（指拜登）要搞死他的冤家对 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/7a9397919843931b0851b7906725c628/?utm_source=see_also&utm_medium=%25E6%2594%25BF%25E5%25BA%259C%25E7%25A9%25B6%25E7%25AB%259F%25E8%25AF%25A5%25E5%25A6%2582%25E4%25BD%2595%25E7%259B%2591%25E7%25AE%25A1%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BD">“入脑嚼髓”的微塑料究竟有多可怕？</a></h2><p class=text-dark>“入脑嚼髓”的微塑料究竟有多可怕？
作者：王晨光
“研究首次证实，人体已经被塑料污染。”
“科学家在人体大脑内发现塑料微粒！”
“从你喝的水开始, 塑料就在慢慢地侵袭你的身体。”
……
金庸小说《笑傲江湖》中描述了一种用于控制人的神药“三尸 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/3a6871a717fa7c36e3bb7824af842164/?utm_source=see_also&utm_medium=%25E6%2594%25BF%25E5%25BA%259C%25E7%25A9%25B6%25E7%25AB%259F%25E8%25AF%25A5%25E5%25A6%2582%25E4%25BD%2595%25E7%259B%2591%25E7%25AE%25A1%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BD">生命、自由、追求幸福和革命的权利</a></h2><p class=text-dark>生命、自由、追求幸福和革命的权利
·方舟子·
7月4日是美国独立节，纪念美国国父们签署《独立宣言》。《独立宣言》是托马斯·杰斐逊起草的，主要内容都是控诉英国国王多么多么的坏，我们不想再让他统治了，要求脱离英国独立。如果《独立宣言》只有这方面 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/f22e4f5dbce41aefc8aa4b7faa6df950/?utm_source=see_also&utm_medium=%25E6%2594%25BF%25E5%25BA%259C%25E7%25A9%25B6%25E7%25AB%259F%25E8%25AF%25A5%25E5%25A6%2582%25E4%25BD%2595%25E7%259B%2591%25E7%25AE%25A1%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BD">人工智能能有多可怕？</a></h2><p class=text-dark>人工智能能有多可怕？
·方舟子·
一批研发人工智能的科学家、工程师、业界领袖联合发表声明，警告人们：人工智能有造成灭绝人类的风险。这个声明是放在网上征集签名的，签名的人数会越来越多，现在已有300多人签名。其中包括研发出ChatGPT …</p></article></div></div></div></div></div></div></div></div></section><script>var i,images=document.getElementsByTagName("img");for(i=0;i<images.length;i++)images[i].className+="img-fluid w-100 mb-4"</script><footer class="py-4 bg-light border-top"><div class=container><div class="row justify-content-between align-items-center"><div class="col-lg-4 text-center text-lg-left mb-4 mb-lg-0"><a href=https://project-gutenberg.github.io/Pincong/><img src=https://project-gutenberg.github.io/Pincong//images/logo.png class=img-fluid alt=品葱*精选></a></div><div class="col-lg-4 text-center mb-4 mb-lg-0"><ul class="list-inline mb-0"></ul></div><div class="col-lg-4 text-lg-right text-center mb-4 mb-lg-0"><ul class="list-inline social-icon mb-0"><li class=list-inline-item><a href=https://pincong.rocks/><i class=ti-home></i></a></li><li class=list-inline-item><a href=https://github.com/Project-Gutenberg/Pincong><i class=ti-github></i></a></li></ul></div><div class="col-12 text-center mt-4"><span></span></div></div></div></footer><script src=../../plugins/jQuery/jquery.min.js></script>
<script src=../../plugins/bootstrap/bootstrap.min.js></script>
<script src=../../plugins/search/fuse.min.js></script>
<script src=../../plugins/search/mark.js></script>
<script src=../../plugins/search/search.js></script>
<script src=https://project-gutenberg.github.io/Pincong/js/script.min.js></script>
<script>(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)})(window,document,'script','//www.google-analytics.com/analytics.js','ga'),ga('create','UA-151212685-6','auto'),ga('send','pageview')</script></body></html>