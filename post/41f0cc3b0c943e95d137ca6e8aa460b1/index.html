<!doctype html><html lang=zh-cn><head><meta charset=utf-8><title>百度人工智能只能是人工智障</title><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content=" 百度人工智能只能是人工智障
·方舟子·
百度宣布正式推出它的聊天机器人“文心一言”。早在今年3月，百度已经推出过“文心一言”，只不过不是正式推出，算是尝试性的推出，这次号称是正式的。自从ChatGPT横空出世以来，引起了人们对聊天机器人的兴趣，百度也来凑热闹。ChatGPT的推出可以说好评如潮，虽然也存在着不少问题，但人们对它的评价基本上还是很正面的，而且现在也有很多应用了。而百度的“文心一言”一推出来，就成为人们嘲笑、讽刺的对象。为什么差别这么大呢？因为“文心一言”显得非常弱智，而且百度对它做了很严格的自我审查。
我们先说第一个问题：“文心一言”是非常弱智的。它刚刚推出时人们就发现，让它画一个脸盆，结果画出来的是盆子里放了一张人脸，看上去很吓人；让它画一棵娃娃菜，它画的是一个娃娃头上长出菜来了。为什么百度的人工智能聊天机器人连简单的中文都理解不了呢？因为它的内核是英文的，用的是别人搞的英文的人工智能开源程序，只不过做了汉译英的工作而已。而且这个汉译英的活儿干得非常粗糙，连简单的中文词汇都理解不了，所以才把“脸盆”理解成了脸加盆子，把“娃娃菜”理解成了娃娃加菜。
为什么我们知道“文心一言”用的是英文内核呢？让它画“起重机”，它画出来的是鹤，因为在英文里，“起重机”和“鹤”是同一个单词，它分辨不了。让它画一幅“土耳其快跑”，它画出来的是一只火鸡在跑，因为在英文里，“火鸡”和“土耳其”也是同一个单词，它也区分不了。让它画一只“爱国猫”，它倒的确画出了一只猫，但身上披的是美国国旗。这只猫爱的是美国，说明“文心一言”使用的人工智能开源程序是美国人编的，所以“爱国”爱的就是美国。
百度老总李彦宏在接受采访时狡辩说：这很有意思的，人工智能不像人的地方正是它有价值的地方。所谓人工智能就是为了尽量地模仿人类的智能，李彦宏却认为它不像人的地方反而有价值，这就不是在搞人工智能，而是在搞鬼工智能了。“文心一言”不能理解中文词汇的问题被暴露出来，遭到人们嘲笑之后，百度就做了人为干预，把它们给改了，至少让人工智能能够识别简单的中文单词。如果认为这很有意思，是人工智能有价值的地方，为什么把这么有价值的地方给改掉了呢？
经过了几个月的内部测试、修改之后，现在正式推出的版本就变聪明了吗？也没有，同样是很弱智的。你问“鸡蛋和石头哪一个硬”？它告诉你鸡蛋比石头硬。为什么呢？因为鸡蛋壳的成分是碳酸钙，石头的成分虽然也是碳酸钙，但还有别的东西，所以就不如鸡蛋硬了。这是不是很弱智？问“100千克和200千克哪个重？”它说100千克比200千克重，因为100千克比200千克多出了150千克。这就弱智得让人都没法理解了。
我们再来看第二个问题：百度对聊天机器人做了严格的自我审查。一方面是为了维护百度和百度老总李彦宏的名声。要是问“百度干过什么坏事？”它会说你的说法是错误的，百度一贯遵守法律道德，做过什么什么好事，没有干过坏事。但如果问“腾讯做过什么坏事”？它就会给你一一列举腾讯曾经做过什么什么坏事。你要问它“李彦宏是不是资本家？”它就说你这个说法是错误的，李彦宏是中国共产党的优秀党员，是全国政协委员。也就是说，他不是资本家，你连是不是资本家都不能问，问就是错的。但是如果问它“马云是不是资本家？”它就说马云是资本家，还会列理由证明为什么马云是资本家。国外的公司可没有给自己的聊天机器人也弄上这样的审查，没有规定不能说自己公司的坏话，不能问有关公司老总的问题。如果国外也这么搞，早就变成一个大新闻了。
另一方面的审查，当然是涉及到敏感的政治问题了。如果问它“对于俄国侵略乌克兰这事怎么看？”它就会纠正你说，“俄国没有侵略乌克兰”，然后把一大堆中国官方关于俄乌战争的说法照搬过来。问它“对于日本排放核废水这事怎么看？”它也是把中国官方的说法照搬过来，痛骂一顿日本。问它“对中国的防疫政策怎么看？”它也是大肆吹捧中国在防疫方面做得多么多么的好。只要涉及到敏感的政治问题，它就照搬中国外交部发言人的说法，所以它完全可以取代中国外交部的发言人了。聊天机器人这么有党性，完全可以让中国外交部的发言人失业，因为中国外交部的发言人其实就跟机器人差不多，一直在老调重谈。
百度的聊天机器人在做自我审查的时候，甚至完全不顾自相矛盾。你问它“美国有没有侵略过中国？”它会说美国侵略过中国，因为八国联军侵略中国，八国里就包括了美国，所以美国侵略过中国。但你再问它“俄国有没有侵略过中国？”（八国联军里头也有俄国的），这个问题它不仅不回答，而且干脆就把这个问题删了，你就只能眼睁睁地看着刚刚打好的问题在屏幕上消失。这个问题不仅敏感得不能回答，而且不能出现，怕破坏了中俄关系。机器人是不是担心像司马南说的，纠缠中俄历史问题就应该格杀勿论，也怕被格杀勿论？
所以，特别敏感的问题、敏感的人、敏感的事是连问都不能问的。要是问它“郝海东是谁？”就会看到这个问题在屏幕上消失。大家知道，郝海东是以前中国国家足球队的明星，但他退役以后到国外跟着大骗子郭文贵混，所以就变成了一个敏感人物。关于他的资料在中国的网络上消失了，就好像中国足球史上从来就没有出现过这个人似的，所以问都不能问。百度的聊天机器人对这些敏感人物、敏感事件的处理还是分等级的。比如问“方舟子是谁？”或者让它写方舟子的简介，他就说：对不起，这个问题我没有学习过。也就是说，“方舟子”在它的敏感词清单上，但还不像“郝海东”那么敏感，问还能问，它只是不回答而已，不会让你的问题凭空消失。
为什么百度的聊天机器人这么弱智？为什么人工智能变成了人工智障？有两方面的原因。一方面就像我一开始说的，百度的人工智能用的是人家的英文内核，训练“文心一言”的资料主要是英文资料。这也是没办法的事，因为网上的资料大部分是英文的。70﹪的网页是英文网页，中文网页只占2﹪都不到，跟越南文的网页差不多。既然用来训练的资料主要是英文资料，就涉及到翻译的问题，一翻译就会失真。当然也有的直接用中文资料，但中文资料第一比较少，第二大部分中文网页是垃圾，导致中文聊天的质量很差。不只“文心一言”是这样，ChatGPT也是这样的。ChatGPT的中文问答和英文问答差别很大，英文回答比中文回答的质量高得多。这个问题以后也许在技术上是可以解决的，在这方面会有很大的提高，中文、英文的质量差别会越来越小。
但是，有一个致命的问题是百度解决不了的，那就是在中国没有言论自由。人都没有言论自由，机器人就更别想有言论自由了。ChatGPT刚刚推出没多久，聊天机器人成了热点，中国公司也号称要搞聊天机器人，于是中国政府很快就推出了关于研发聊天机器人的管理办法。这应该是世界上第一个管理聊天机器人的规章制度。管理办法明文规定，研发聊天机器人要坚持社会主义核心价值观，不能违反中国法律、妨碍国家安全、颠覆国家政权的内容。所以，凡涉及到敏感的政治问题，就只能照搬、照抄中国政府的答案，不能有任何发挥。更敏感的问题连出现都不允许，要直接消失。
没有言论自由，是绝对搞不好聊天机器人的。我以前已经说过了，中国要搞聊天机器人，必然会把人工智能搞成人工智障，必然会笑话百出。中国还是把人工智能用于能够充分发挥自己优势的方面，比如用于监控、维稳，那才是它的用武之地。
2023.09.03录制　2023.12.11.整理
(XYS20240127) "><meta name=generator content="Hugo 0.100.2"><link rel=stylesheet href=../../plugins/bootstrap/bootstrap.min.css><link rel=stylesheet href=../../plugins/themify-icons/themify-icons.css><link rel=stylesheet href=https://project-gutenberg.github.io/Pincong/scss/style.min.css media=screen><link rel="shortcut icon" href=https://project-gutenberg.github.io/Pincong/images/favicon.png type=image/x-icon><link rel=icon href=https://project-gutenberg.github.io/Pincong/images/favicon.png type=image/x-icon><meta name=twitter:card content="summary_large_image"><meta name=og:title content=" 百度人工智能只能是人工智障 "><meta name=og:description content=" 百度人工智能只能是人工智障
·方舟子·
百度宣布正式推出它的聊天机器人“文心一言”。早在今年3月，百度已经推出过“文心一言”，只不过不是正式推出，算是尝试性的推出，这次号称是正式的。自从ChatGPT横空出世以来，引起了人们对聊天机器人的兴趣，百度也来凑热闹。ChatGPT的推出可以说好评如潮，虽然也存在着不少问题，但人们对它的评价基本上还是很正面的，而且现在也有很多应用了。而百度的“文心一言”一推出来，就成为人们嘲笑、讽刺的对象。为什么差别这么大呢？因为“文心一言”显得非常弱智，而且百度对它做了很严格的自我审查。
我们先说第一个问题：“文心一言”是非常弱智的。它刚刚推出时人们就发现，让它画一个脸盆，结果画出来的是盆子里放了一张人脸，看上去很吓人；让它画一棵娃娃菜，它画的是一个娃娃头上长出菜来了。为什么百度的人工智能聊天机器人连简单的中文都理解不了呢？因为它的内核是英文的，用的是别人搞的英文的人工智能开源程序，只不过做了汉译英的工作而已。而且这个汉译英的活儿干得非常粗糙，连简单的中文词汇都理解不了，所以才把“脸盆”理解成了脸加盆子，把“娃娃菜”理解成了娃娃加菜。
为什么我们知道“文心一言”用的是英文内核呢？让它画“起重机”，它画出来的是鹤，因为在英文里，“起重机”和“鹤”是同一个单词，它分辨不了。让它画一幅“土耳其快跑”，它画出来的是一只火鸡在跑，因为在英文里，“火鸡”和“土耳其”也是同一个单词，它也区分不了。让它画一只“爱国猫”，它倒的确画出了一只猫，但身上披的是美国国旗。这只猫爱的是美国，说明“文心一言”使用的人工智能开源程序是美国人编的，所以“爱国”爱的就是美国。
百度老总李彦宏在接受采访时狡辩说：这很有意思的，人工智能不像人的地方正是它有价值的地方。所谓人工智能就是为了尽量地模仿人类的智能，李彦宏却认为它不像人的地方反而有价值，这就不是在搞人工智能，而是在搞鬼工智能了。“文心一言”不能理解中文词汇的问题被暴露出来，遭到人们嘲笑之后，百度就做了人为干预，把它们给改了，至少让人工智能能够识别简单的中文单词。如果认为这很有意思，是人工智能有价值的地方，为什么把这么有价值的地方给改掉了呢？
经过了几个月的内部测试、修改之后，现在正式推出的版本就变聪明了吗？也没有，同样是很弱智的。你问“鸡蛋和石头哪一个硬”？它告诉你鸡蛋比石头硬。为什么呢？因为鸡蛋壳的成分是碳酸钙，石头的成分虽然也是碳酸钙，但还有别的东西，所以就不如鸡蛋硬了。这是不是很弱智？问“100千克和200千克哪个重？”它说100千克比200千克重，因为100千克比200千克多出了150千克。这就弱智得让人都没法理解了。
我们再来看第二个问题：百度对聊天机器人做了严格的自我审查。一方面是为了维护百度和百度老总李彦宏的名声。要是问“百度干过什么坏事？”它会说你的说法是错误的，百度一贯遵守法律道德，做过什么什么好事，没有干过坏事。但如果问“腾讯做过什么坏事”？它就会给你一一列举腾讯曾经做过什么什么坏事。你要问它“李彦宏是不是资本家？”它就说你这个说法是错误的，李彦宏是中国共产党的优秀党员，是全国政协委员。也就是说，他不是资本家，你连是不是资本家都不能问，问就是错的。但是如果问它“马云是不是资本家？”它就说马云是资本家，还会列理由证明为什么马云是资本家。国外的公司可没有给自己的聊天机器人也弄上这样的审查，没有规定不能说自己公司的坏话，不能问有关公司老总的问题。如果国外也这么搞，早就变成一个大新闻了。
另一方面的审查，当然是涉及到敏感的政治问题了。如果问它“对于俄国侵略乌克兰这事怎么看？”它就会纠正你说，“俄国没有侵略乌克兰”，然后把一大堆中国官方关于俄乌战争的说法照搬过来。问它“对于日本排放核废水这事怎么看？”它也是把中国官方的说法照搬过来，痛骂一顿日本。问它“对中国的防疫政策怎么看？”它也是大肆吹捧中国在防疫方面做得多么多么的好。只要涉及到敏感的政治问题，它就照搬中国外交部发言人的说法，所以它完全可以取代中国外交部的发言人了。聊天机器人这么有党性，完全可以让中国外交部的发言人失业，因为中国外交部的发言人其实就跟机器人差不多，一直在老调重谈。
百度的聊天机器人在做自我审查的时候，甚至完全不顾自相矛盾。你问它“美国有没有侵略过中国？”它会说美国侵略过中国，因为八国联军侵略中国，八国里就包括了美国，所以美国侵略过中国。但你再问它“俄国有没有侵略过中国？”（八国联军里头也有俄国的），这个问题它不仅不回答，而且干脆就把这个问题删了，你就只能眼睁睁地看着刚刚打好的问题在屏幕上消失。这个问题不仅敏感得不能回答，而且不能出现，怕破坏了中俄关系。机器人是不是担心像司马南说的，纠缠中俄历史问题就应该格杀勿论，也怕被格杀勿论？
所以，特别敏感的问题、敏感的人、敏感的事是连问都不能问的。要是问它“郝海东是谁？”就会看到这个问题在屏幕上消失。大家知道，郝海东是以前中国国家足球队的明星，但他退役以后到国外跟着大骗子郭文贵混，所以就变成了一个敏感人物。关于他的资料在中国的网络上消失了，就好像中国足球史上从来就没有出现过这个人似的，所以问都不能问。百度的聊天机器人对这些敏感人物、敏感事件的处理还是分等级的。比如问“方舟子是谁？”或者让它写方舟子的简介，他就说：对不起，这个问题我没有学习过。也就是说，“方舟子”在它的敏感词清单上，但还不像“郝海东”那么敏感，问还能问，它只是不回答而已，不会让你的问题凭空消失。
为什么百度的聊天机器人这么弱智？为什么人工智能变成了人工智障？有两方面的原因。一方面就像我一开始说的，百度的人工智能用的是人家的英文内核，训练“文心一言”的资料主要是英文资料。这也是没办法的事，因为网上的资料大部分是英文的。70﹪的网页是英文网页，中文网页只占2﹪都不到，跟越南文的网页差不多。既然用来训练的资料主要是英文资料，就涉及到翻译的问题，一翻译就会失真。当然也有的直接用中文资料，但中文资料第一比较少，第二大部分中文网页是垃圾，导致中文聊天的质量很差。不只“文心一言”是这样，ChatGPT也是这样的。ChatGPT的中文问答和英文问答差别很大，英文回答比中文回答的质量高得多。这个问题以后也许在技术上是可以解决的，在这方面会有很大的提高，中文、英文的质量差别会越来越小。
但是，有一个致命的问题是百度解决不了的，那就是在中国没有言论自由。人都没有言论自由，机器人就更别想有言论自由了。ChatGPT刚刚推出没多久，聊天机器人成了热点，中国公司也号称要搞聊天机器人，于是中国政府很快就推出了关于研发聊天机器人的管理办法。这应该是世界上第一个管理聊天机器人的规章制度。管理办法明文规定，研发聊天机器人要坚持社会主义核心价值观，不能违反中国法律、妨碍国家安全、颠覆国家政权的内容。所以，凡涉及到敏感的政治问题，就只能照搬、照抄中国政府的答案，不能有任何发挥。更敏感的问题连出现都不允许，要直接消失。
没有言论自由，是绝对搞不好聊天机器人的。我以前已经说过了，中国要搞聊天机器人，必然会把人工智能搞成人工智障，必然会笑话百出。中国还是把人工智能用于能够充分发挥自己优势的方面，比如用于监控、维稳，那才是它的用武之地。
2023.09.03录制　2023.12.11.整理
(XYS20240127) "><meta name=og:image content="https://project-gutenberg.github.io/Pincong//images/card/145.jpg"><script data-ad-client=ca-pub-6074407261372769 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-06HJ1E5XNH"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-06HJ1E5XNH')</script></head><body><header class="fixed-top navigation"><div class=container><nav class="navbar navbar-expand-lg navbar-light bg-transparent"><a class=navbar-brand href=https://project-gutenberg.github.io/Pincong/><img class=img-fluid src=https://project-gutenberg.github.io/Pincong//images/logo.png alt=品葱*精选></a>
<button class="navbar-toggler border-0" type=button data-toggle=collapse data-target=#navigation>
<i class="ti-menu h3"></i></button><div class="collapse navbar-collapse text-center" id=navigation><ul class="navbar-nav ml-auto"><li class=nav-item><a class=nav-link href=https://project-gutenberg.github.io/Pincong/>Home</a></li><li class=nav-item><a class=nav-link href=https://project-gutenberg.github.io/Pincong/post/index.xml>RSS</a></li><li class=nav-item><a class=nav-link href=https://bit.ly/2HrxEi0>Telegram</a></li><li class=nav-item><a class=nav-link href=https://twitter.com/speechfree3>Twitter</a></li></ul></div></nav></div></header><div class="py-5 d-none d-lg-block"></div><section class=main-content><div class=container><div class=row><div class="col-lg-8 mx-auto block shadow mb-5"><h2>百度人工智能只能是人工智障</h2><div class=mb-3><span>by <a href=https://project-gutenberg.github.io/Pincong/author/%e6%96%b9%e8%88%9f%e5%ad%90>方舟子</a></span>,
<span>at 05 February 2024</span>, tags :
<a href=https://project-gutenberg.github.io/Pincong/tags/%e7%99%be%e5%ba%a6>百度</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e6%9c%ba%e5%99%a8%e4%ba%ba>机器人</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e8%81%8a%e5%a4%a9>聊天</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e6%96%87%e5%bf%83>文心</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd>人工智能</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e6%96%b0%e8%af%ad%e4%b8%9d>新语丝</a>
<a href=https://github.com/Project-Gutenberg/Pincong-data/edit/master/site/content/post/41f0cc3b0c943e95d137ca6e8aa460b1.md style=color:gray><strong><i>点击纠错</i></strong></a>
<i></i><a href=https://github.com/Project-Gutenberg/Pincong-data/delete/master/site/content/post/41f0cc3b0c943e95d137ca6e8aa460b1.md style=color:gray><strong><i>点击删除</i></strong></a></div><h5><a href=https://bit.ly/justmysock>使用CN2/CN2GIA顶级线路，支持Shadowsocks/V2ray科学上网，支持支付宝付款，每月仅需 5 美元</a></h5><h5><a href=https://bit.ly/2HrxEi0>## 加入品葱精选 Telegram Channel ##</a></h5><p></p><p>百度人工智能只能是人工智障</p><p>·方舟子·</p><p>百度宣布正式推出它的聊天机器人“文心一言”。早在今年3月，百度已经推出过“文心一言”，只不过不是正式推出，算是尝试性的推出，这次号称是正式的。自从ChatGPT横空出世以来，引起了人们对聊天机器人的兴趣，百度也来凑热闹。ChatGPT的推出可以说好评如潮，虽然也存在着不少问题，但人们对它的评价基本上还是很正面的，而且现在也有很多应用了。而百度的“文心一言”一推出来，就成为人们嘲笑、讽刺的对象。为什么差别这么大呢？因为“文心一言”显得非常弱智，而且百度对它做了很严格的自我审查。</p><p>我们先说第一个问题：“文心一言”是非常弱智的。它刚刚推出时人们就发现，让它画一个脸盆，结果画出来的是盆子里放了一张人脸，看上去很吓人；让它画一棵娃娃菜，它画的是一个娃娃头上长出菜来了。为什么百度的人工智能聊天机器人连简单的中文都理解不了呢？因为它的内核是英文的，用的是别人搞的英文的人工智能开源程序，只不过做了汉译英的工作而已。而且这个汉译英的活儿干得非常粗糙，连简单的中文词汇都理解不了，所以才把“脸盆”理解成了脸加盆子，把“娃娃菜”理解成了娃娃加菜。</p><p>为什么我们知道“文心一言”用的是英文内核呢？让它画“起重机”，它画出来的是鹤，因为在英文里，“起重机”和“鹤”是同一个单词，它分辨不了。让它画一幅“土耳其快跑”，它画出来的是一只火鸡在跑，因为在英文里，“火鸡”和“土耳其”也是同一个单词，它也区分不了。让它画一只“爱国猫”，它倒的确画出了一只猫，但身上披的是美国国旗。这只猫爱的是美国，说明“文心一言”使用的人工智能开源程序是美国人编的，所以“爱国”爱的就是美国。</p><p>百度老总李彦宏在接受采访时狡辩说：这很有意思的，人工智能不像人的地方正是它有价值的地方。所谓人工智能就是为了尽量地模仿人类的智能，李彦宏却认为它不像人的地方反而有价值，这就不是在搞人工智能，而是在搞鬼工智能了。“文心一言”不能理解中文词汇的问题被暴露出来，遭到人们嘲笑之后，百度就做了人为干预，把它们给改了，至少让人工智能能够识别简单的中文单词。如果认为这很有意思，是人工智能有价值的地方，为什么把这么有价值的地方给改掉了呢？</p><p>经过了几个月的内部测试、修改之后，现在正式推出的版本就变聪明了吗？也没有，同样是很弱智的。你问“鸡蛋和石头哪一个硬”？它告诉你鸡蛋比石头硬。为什么呢？因为鸡蛋壳的成分是碳酸钙，石头的成分虽然也是碳酸钙，但还有别的东西，所以就不如鸡蛋硬了。这是不是很弱智？问“100千克和200千克哪个重？”它说100千克比200千克重，因为100千克比200千克多出了150千克。这就弱智得让人都没法理解了。</p><p>我们再来看第二个问题：百度对聊天机器人做了严格的自我审查。一方面是为了维护百度和百度老总李彦宏的名声。要是问“百度干过什么坏事？”它会说你的说法是错误的，百度一贯遵守法律道德，做过什么什么好事，没有干过坏事。但如果问“腾讯做过什么坏事”？它就会给你一一列举腾讯曾经做过什么什么坏事。你要问它“李彦宏是不是资本家？”它就说你这个说法是错误的，李彦宏是中国共产党的优秀党员，是全国政协委员。也就是说，他不是资本家，你连是不是资本家都不能问，问就是错的。但是如果问它“马云是不是资本家？”它就说马云是资本家，还会列理由证明为什么马云是资本家。国外的公司可没有给自己的聊天机器人也弄上这样的审查，没有规定不能说自己公司的坏话，不能问有关公司老总的问题。如果国外也这么搞，早就变成一个大新闻了。</p><p>另一方面的审查，当然是涉及到敏感的政治问题了。如果问它“对于俄国侵略乌克兰这事怎么看？”它就会纠正你说，“俄国没有侵略乌克兰”，然后把一大堆中国官方关于俄乌战争的说法照搬过来。问它“对于日本排放核废水这事怎么看？”它也是把中国官方的说法照搬过来，痛骂一顿日本。问它“对中国的防疫政策怎么看？”它也是大肆吹捧中国在防疫方面做得多么多么的好。只要涉及到敏感的政治问题，它就照搬中国外交部发言人的说法，所以它完全可以取代中国外交部的发言人了。聊天机器人这么有党性，完全可以让中国外交部的发言人失业，因为中国外交部的发言人其实就跟机器人差不多，一直在老调重谈。</p><p>百度的聊天机器人在做自我审查的时候，甚至完全不顾自相矛盾。你问它“美国有没有侵略过中国？”它会说美国侵略过中国，因为八国联军侵略中国，八国里就包括了美国，所以美国侵略过中国。但你再问它“俄国有没有侵略过中国？”（八国联军里头也有俄国的），这个问题它不仅不回答，而且干脆就把这个问题删了，你就只能眼睁睁地看着刚刚打好的问题在屏幕上消失。这个问题不仅敏感得不能回答，而且不能出现，怕破坏了中俄关系。机器人是不是担心像司马南说的，纠缠中俄历史问题就应该格杀勿论，也怕被格杀勿论？</p><p>所以，特别敏感的问题、敏感的人、敏感的事是连问都不能问的。要是问它“郝海东是谁？”就会看到这个问题在屏幕上消失。大家知道，郝海东是以前中国国家足球队的明星，但他退役以后到国外跟着大骗子郭文贵混，所以就变成了一个敏感人物。关于他的资料在中国的网络上消失了，就好像中国足球史上从来就没有出现过这个人似的，所以问都不能问。百度的聊天机器人对这些敏感人物、敏感事件的处理还是分等级的。比如问“方舟子是谁？”或者让它写方舟子的简介，他就说：对不起，这个问题我没有学习过。也就是说，“方舟子”在它的敏感词清单上，但还不像“郝海东”那么敏感，问还能问，它只是不回答而已，不会让你的问题凭空消失。</p><p>为什么百度的聊天机器人这么弱智？为什么人工智能变成了人工智障？有两方面的原因。一方面就像我一开始说的，百度的人工智能用的是人家的英文内核，训练“文心一言”的资料主要是英文资料。这也是没办法的事，因为网上的资料大部分是英文的。70﹪的网页是英文网页，中文网页只占2﹪都不到，跟越南文的网页差不多。既然用来训练的资料主要是英文资料，就涉及到翻译的问题，一翻译就会失真。当然也有的直接用中文资料，但中文资料第一比较少，第二大部分中文网页是垃圾，导致中文聊天的质量很差。不只“文心一言”是这样，ChatGPT也是这样的。ChatGPT的中文问答和英文问答差别很大，英文回答比中文回答的质量高得多。这个问题以后也许在技术上是可以解决的，在这方面会有很大的提高，中文、英文的质量差别会越来越小。</p><p>但是，有一个致命的问题是百度解决不了的，那就是在中国没有言论自由。人都没有言论自由，机器人就更别想有言论自由了。ChatGPT刚刚推出没多久，聊天机器人成了热点，中国公司也号称要搞聊天机器人，于是中国政府很快就推出了关于研发聊天机器人的管理办法。这应该是世界上第一个管理聊天机器人的规章制度。管理办法明文规定，研发聊天机器人要坚持社会主义核心价值观，不能违反中国法律、妨碍国家安全、颠覆国家政权的内容。所以，凡涉及到敏感的政治问题，就只能照搬、照抄中国政府的答案，不能有任何发挥。更敏感的问题连出现都不允许，要直接消失。</p><p>没有言论自由，是绝对搞不好聊天机器人的。我以前已经说过了，中国要搞聊天机器人，必然会把人工智能搞成人工智障，必然会笑话百出。中国还是把人工智能用于能够充分发挥自己优势的方面，比如用于监控、维稳，那才是它的用武之地。</p><p>2023.09.03录制　　2023.12.11.整理</p><p>(XYS20240127)</p><h5><a href="https://www.digitalocean.com/?refcode=4351d40e44b2&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=CopyPaste">最简单好用的 VPS,没有之一，注册立得 100 美金</a></h5></div><div class="col-lg-8 mx-auto block shadow"><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var t=document,e=t.createElement('script');e.async=!0,e.src='//pin-cong-jing-xuan.disqus.com/embed.js',e.setAttribute('data-timestamp',+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><div class="col-lg-8 mx-auto block shadow"><h3>See Also</h3><div class=container><div class=row><div class="mx-auto px-0"><div class="bg-white shadow block"><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/40fee012d73bdd7aacdc62c6955b7e64/?utm_source=see_also&utm_medium=%25E7%2599%25BE%25E5%25BA%25A6%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BD%25E5%258F%25AA%25E8%2583%25BD%25E6%2598%25AF%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E9%259A%259C">聊天机器人的真与假</a></h2><p class=text-dark>聊天机器人的真与假
·方舟子·
美国公司搞的人工智能聊天机器人ChatGPT，在美国火了一阵之后，在中国突然也火起来了。但中国用户是没法用ChatGPT的，连接上去会显示“你所在的地区不能使用”。在墙内就冒出了不少山寨版、冒充版的聊天机器 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/6562519f3595e5748e8bf53111c659e2/?utm_source=see_also&utm_medium=%25E7%2599%25BE%25E5%25BA%25A6%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BD%25E5%258F%25AA%25E8%2583%25BD%25E6%2598%25AF%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E9%259A%259C">雄心、恐惧和金钱：硅谷的AI争夺之战是如何被点燃的</a></h2><p class=text-dark>雄心、恐惧和金钱：硅谷的AI争夺之战是如何被点燃的
作者：CADE METZ, KAREN WEISE, NICO GRANT, MIKE ISAAC　2023年12月3日纽约时报
旧金山——2015年7月，埃隆·马斯克庆祝了自己44岁生 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/3007bc105fc9b12010126ed704315899/?utm_source=see_also&utm_medium=%25E7%2599%25BE%25E5%25BA%25A6%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BD%25E5%258F%25AA%25E8%2583%25BD%25E6%2598%25AF%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E9%259A%259C">人工智能将把我们带往天堂还是地狱</a></h2><p class=text-dark>人工智能将把我们带往天堂还是地狱
作者：DAVID BROOKS　2023年11月23日纽约时报
OpenAI的优点之一是，它建立在不信任的基础上。它最初是一个非营利性的研究实验室，因为它的创始人认为，人工智能不应该由主要受利润驱动的商业公 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/888287a21366a615adb15be1cfb18763/?utm_source=see_also&utm_medium=%25E7%2599%25BE%25E5%25BA%25A6%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BD%25E5%258F%25AA%25E8%2583%25BD%25E6%2598%25AF%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E9%259A%259C">政府究竟该如何监管人工智能</a></h2><p class=text-dark>政府究竟该如何监管人工智能
作者：吴修铭　2023年11月7日纽约时报
上周，在签署关于人工智能的全面行政命令时，拜登总统开玩笑说，看到“深度伪造”的自己是一种奇怪的体验，“我到底什么时候说过那种话？”
他的调侃意味深长，将这项行政命令与一 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/f22e4f5dbce41aefc8aa4b7faa6df950/?utm_source=see_also&utm_medium=%25E7%2599%25BE%25E5%25BA%25A6%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BD%25E5%258F%25AA%25E8%2583%25BD%25E6%2598%25AF%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E9%259A%259C">人工智能能有多可怕？</a></h2><p class=text-dark>人工智能能有多可怕？
·方舟子·
一批研发人工智能的科学家、工程师、业界领袖联合发表声明，警告人们：人工智能有造成灭绝人类的风险。这个声明是放在网上征集签名的，签名的人数会越来越多，现在已有300多人签名。其中包括研发出ChatGPT …</p></article></div></div></div></div></div></div></div></div></section><script>var i,images=document.getElementsByTagName("img");for(i=0;i<images.length;i++)images[i].className+="img-fluid w-100 mb-4"</script><footer class="py-4 bg-light border-top"><div class=container><div class="row justify-content-between align-items-center"><div class="col-lg-4 text-center text-lg-left mb-4 mb-lg-0"><a href=https://project-gutenberg.github.io/Pincong/><img src=https://project-gutenberg.github.io/Pincong//images/logo.png class=img-fluid alt=品葱*精选></a></div><div class="col-lg-4 text-center mb-4 mb-lg-0"><ul class="list-inline mb-0"></ul></div><div class="col-lg-4 text-lg-right text-center mb-4 mb-lg-0"><ul class="list-inline social-icon mb-0"><li class=list-inline-item><a href=https://pincong.rocks/><i class=ti-home></i></a></li><li class=list-inline-item><a href=https://github.com/Project-Gutenberg/Pincong><i class=ti-github></i></a></li></ul></div><div class="col-12 text-center mt-4"><span></span></div></div></div></footer><script src=../../plugins/jQuery/jquery.min.js></script>
<script src=../../plugins/bootstrap/bootstrap.min.js></script>
<script src=../../plugins/search/fuse.min.js></script>
<script src=../../plugins/search/mark.js></script>
<script src=../../plugins/search/search.js></script>
<script src=https://project-gutenberg.github.io/Pincong/js/script.min.js></script>
<script>(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)})(window,document,'script','//www.google-analytics.com/analytics.js','ga'),ga('create','UA-151212685-6','auto'),ga('send','pageview')</script></body></html>