<!doctype html><html lang=zh-cn><head><meta charset=utf-8><title>人工智能能有多可怕？</title><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content=" 人工智能能有多可怕？
·方舟子·
一批研发人工智能的科学家、工程师、业界领袖联合发表声明，警告人们：人工智能有造成灭绝人类的风险。这个声明是放在网上征集签名的，签名的人数会越来越多，现在已有300多人签名。其中包括研发出ChatGPT的OpenAI公司老总、谷歌研发人工智能的DeepMind公司老总，以及两个因研究人工智能获得图灵奖（计算机科学领域的最高奖）的科学家。这个声明很简单，只有一句话：减轻人工智能可能带来的灭绝风险要成为全球优先做的事情，就像对待其他社会级别的风险，例如瘟疫大流行和核武器一样。为什么只有一句话呢？据组织签名的人说，因为这更容易有共识。
人工智能有可能灭绝人类并不是什么新的想法，很早以前就有了。几年前，谷歌研发的AlphaGo打败了李世石，当时就有人说，人工智能再这么搞下去，会变得智力非常高超，会因此把人类消灭了。我当时就说这是危言耸听，是科幻小说、科幻电影看多了。
有人可能会说，你不是搞人工智能的专家，在这方面有什么发言权？难道你比那三百多个研发人工智能的专家、权威对这个问题更懂吗？
人工智能会不会毁灭人类不是一个技术问题，而是一个哲学问题，不需要是人工智能领域的专家也可以对这个问题进行讨论、发表见解。今年三月份，也有一千多人联合发表了一篇声明警告人们，人工智能很危险，呼吁研发人工智能的人暂时停止研发6个月。这一千多人并不都是搞人工智能的，实际上绝大部分不是搞人工智能的，他们也签名了。例如马斯克本身并不搞人工智能，未必懂人工智能，但也签名了。可见对这个问题，不是该领域的专家、权威也有发言权。
而且，关于人工智能会不会灭绝人类，在人工智能领域并没有形成共识。虽然签名的人数有三百多，听上去好像很多，但人工智能是一个非常热门的领域，研发的人非常多，专家、权威也非常多，这三百多人只是其中的一小部分而已。那些研发人工智能的公司并没有都签名，例如脸书下面研发人工智能的公司就没有签名。因研究人工智能获得图灵奖的科学家也并没有都签名。所以这并不是人工智能业界的共识。
这些研发人工智能的人出来警告人们，人工智能有灭绝人类的风险，让人觉得很蹊跷，动机很可疑。他们本身就在研发人工智能，而且是这个领域的领军人物，为什么却要人们警惕人工智能的危险，甚至是灭绝人类这么吓人的危险？他们为什么还要明知故犯去研究一个有可能灭绝人类的、如此恐怖的技术呢？这一方面是要显得自己很自律，站在道德高位；另一方面是希望政府把这个领域管起来。政府的管理对这些领先的公司、人物影响不会太大，对那些黑马影响更大，而这些领先公司、人物就可以一直保持领先的地位。社交媒体领域最大的公司脸书一直在呼吁美国政府把社交媒体管起来，也是同样的理由，一方面显得自己很高尚，另一方面，这个领域真的被管起来，会对别的社交媒体造成更大的负面影响，对已经领先、有着优势地位的公司影响不会很大。
所以，这么呼吁的人其实是言不由衷的，是别有用心的。如果他们真的认为人工智能这么可怕，那么在政府管理之前，他们就应该首先自律，暂停人工智能的研究，就像三月份那1000多个人发的声明里说的，暂停研究人工智能6个月。但三月份发声明的1000多人中也有一部分是研发人工智能的，或者本身不研发但投资人工智能的。比如马斯克，本身不懂人工智能、不研发人工智能，但他投资了至少两家人工智能公司。但是他虽然参与签名呼吁暂停研究6个月，自己投资的公司却没有暂停。这些研发、投资人工智能的，继续在研发、投资人工智能，丝毫没有停下来的迹象，反而竞争更加激烈。发这样的声明是不是显得很虚伪？
人工智能是一项技术，跟其他技术一样，如果被滥用，当然会带来一定的社会问题，造成一定的风险。目前面临着的最大问题是人工智能被用于制造、散布虚假信息。ChatGPT现在非常火，很多人都在使用，但也有很多人不知道ChatGPT提供的信息并不都是准确的，经常会胡编乱造、以假乱真。最近在美国就有一个例子。一个律师使用ChatGPT写答辩词，交给法庭后被法官发现他引用的6个案例都是假的，是ChatGPT胡编出来的。而且，现在用人工智能来制造假照片、假视频已经达到足以乱真的地步，人们识别起来非常麻烦。这个问题会变得越来越严重，是应该重视的。
其次，人工智能的发展会导致一些行业过时，会有相当多的人要失业、转行。这并不是一个新的问题。很多技术的发明、发展都会带来同样的问题，都会导致一些行业消失，很多人失业、转行，人工智能并不是一个例外。还有，人工智能以后有可能被用于帮助研发武器，比如生物武器、化学武器，导致这些武器杀伤力非常强。这是不是说明人工智能会毁灭人类呢？人工智能在这方面只是一个工具而已。研发生物武器、化学武器还要用到别的技术，那么是不是说明这些技术也会导致人类灭绝呢？其实，研发这种能导致人类灭绝的大规模杀伤武器，都是邪恶政权干的，再怎样立法、管理，对他们来说都是不起作用的。而且，早就有灭绝人类的技术了，核武器技术已经有了，没有必要等到人工智能达到多高的程度才会导致人类灭绝。
对于人工智能有可能带来的社会问题，当然要正视，并不是说不存在。我们反对的是危言耸听，把它说得特别严重。这让我想起上世纪七十年代，基因工程刚刚发明，也有一些生物学家把基因工程想象得特别可怕，要求业界自律，呼吁政府管理，结果还真把一些官员吓住了。欧洲对基因工程研究管得非常严，美国则管得很松。结果导致在生物技术领域，美国大大领先欧洲。现在回头来看，基因工程技术已经发展到了相当高的程度，毁灭人类了吗？现在还有哪一个生物学家认为基因工程搞不好就会毁灭人类呢？几十年前的那种担忧，是不是很可笑呢？
2023.05.31录制
2023.07.26整理
(XYS20230805) "><meta name=generator content="Hugo 0.100.2"><link rel=stylesheet href=../../plugins/bootstrap/bootstrap.min.css><link rel=stylesheet href=../../plugins/themify-icons/themify-icons.css><link rel=stylesheet href=https://project-gutenberg.github.io/Pincong/scss/style.min.css media=screen><link rel="shortcut icon" href=https://project-gutenberg.github.io/Pincong/images/favicon.png type=image/x-icon><link rel=icon href=https://project-gutenberg.github.io/Pincong/images/favicon.png type=image/x-icon><meta name=twitter:card content="summary_large_image"><meta name=og:title content=" 人工智能能有多可怕？ "><meta name=og:description content=" 人工智能能有多可怕？
·方舟子·
一批研发人工智能的科学家、工程师、业界领袖联合发表声明，警告人们：人工智能有造成灭绝人类的风险。这个声明是放在网上征集签名的，签名的人数会越来越多，现在已有300多人签名。其中包括研发出ChatGPT的OpenAI公司老总、谷歌研发人工智能的DeepMind公司老总，以及两个因研究人工智能获得图灵奖（计算机科学领域的最高奖）的科学家。这个声明很简单，只有一句话：减轻人工智能可能带来的灭绝风险要成为全球优先做的事情，就像对待其他社会级别的风险，例如瘟疫大流行和核武器一样。为什么只有一句话呢？据组织签名的人说，因为这更容易有共识。
人工智能有可能灭绝人类并不是什么新的想法，很早以前就有了。几年前，谷歌研发的AlphaGo打败了李世石，当时就有人说，人工智能再这么搞下去，会变得智力非常高超，会因此把人类消灭了。我当时就说这是危言耸听，是科幻小说、科幻电影看多了。
有人可能会说，你不是搞人工智能的专家，在这方面有什么发言权？难道你比那三百多个研发人工智能的专家、权威对这个问题更懂吗？
人工智能会不会毁灭人类不是一个技术问题，而是一个哲学问题，不需要是人工智能领域的专家也可以对这个问题进行讨论、发表见解。今年三月份，也有一千多人联合发表了一篇声明警告人们，人工智能很危险，呼吁研发人工智能的人暂时停止研发6个月。这一千多人并不都是搞人工智能的，实际上绝大部分不是搞人工智能的，他们也签名了。例如马斯克本身并不搞人工智能，未必懂人工智能，但也签名了。可见对这个问题，不是该领域的专家、权威也有发言权。
而且，关于人工智能会不会灭绝人类，在人工智能领域并没有形成共识。虽然签名的人数有三百多，听上去好像很多，但人工智能是一个非常热门的领域，研发的人非常多，专家、权威也非常多，这三百多人只是其中的一小部分而已。那些研发人工智能的公司并没有都签名，例如脸书下面研发人工智能的公司就没有签名。因研究人工智能获得图灵奖的科学家也并没有都签名。所以这并不是人工智能业界的共识。
这些研发人工智能的人出来警告人们，人工智能有灭绝人类的风险，让人觉得很蹊跷，动机很可疑。他们本身就在研发人工智能，而且是这个领域的领军人物，为什么却要人们警惕人工智能的危险，甚至是灭绝人类这么吓人的危险？他们为什么还要明知故犯去研究一个有可能灭绝人类的、如此恐怖的技术呢？这一方面是要显得自己很自律，站在道德高位；另一方面是希望政府把这个领域管起来。政府的管理对这些领先的公司、人物影响不会太大，对那些黑马影响更大，而这些领先公司、人物就可以一直保持领先的地位。社交媒体领域最大的公司脸书一直在呼吁美国政府把社交媒体管起来，也是同样的理由，一方面显得自己很高尚，另一方面，这个领域真的被管起来，会对别的社交媒体造成更大的负面影响，对已经领先、有着优势地位的公司影响不会很大。
所以，这么呼吁的人其实是言不由衷的，是别有用心的。如果他们真的认为人工智能这么可怕，那么在政府管理之前，他们就应该首先自律，暂停人工智能的研究，就像三月份那1000多个人发的声明里说的，暂停研究人工智能6个月。但三月份发声明的1000多人中也有一部分是研发人工智能的，或者本身不研发但投资人工智能的。比如马斯克，本身不懂人工智能、不研发人工智能，但他投资了至少两家人工智能公司。但是他虽然参与签名呼吁暂停研究6个月，自己投资的公司却没有暂停。这些研发、投资人工智能的，继续在研发、投资人工智能，丝毫没有停下来的迹象，反而竞争更加激烈。发这样的声明是不是显得很虚伪？
人工智能是一项技术，跟其他技术一样，如果被滥用，当然会带来一定的社会问题，造成一定的风险。目前面临着的最大问题是人工智能被用于制造、散布虚假信息。ChatGPT现在非常火，很多人都在使用，但也有很多人不知道ChatGPT提供的信息并不都是准确的，经常会胡编乱造、以假乱真。最近在美国就有一个例子。一个律师使用ChatGPT写答辩词，交给法庭后被法官发现他引用的6个案例都是假的，是ChatGPT胡编出来的。而且，现在用人工智能来制造假照片、假视频已经达到足以乱真的地步，人们识别起来非常麻烦。这个问题会变得越来越严重，是应该重视的。
其次，人工智能的发展会导致一些行业过时，会有相当多的人要失业、转行。这并不是一个新的问题。很多技术的发明、发展都会带来同样的问题，都会导致一些行业消失，很多人失业、转行，人工智能并不是一个例外。还有，人工智能以后有可能被用于帮助研发武器，比如生物武器、化学武器，导致这些武器杀伤力非常强。这是不是说明人工智能会毁灭人类呢？人工智能在这方面只是一个工具而已。研发生物武器、化学武器还要用到别的技术，那么是不是说明这些技术也会导致人类灭绝呢？其实，研发这种能导致人类灭绝的大规模杀伤武器，都是邪恶政权干的，再怎样立法、管理，对他们来说都是不起作用的。而且，早就有灭绝人类的技术了，核武器技术已经有了，没有必要等到人工智能达到多高的程度才会导致人类灭绝。
对于人工智能有可能带来的社会问题，当然要正视，并不是说不存在。我们反对的是危言耸听，把它说得特别严重。这让我想起上世纪七十年代，基因工程刚刚发明，也有一些生物学家把基因工程想象得特别可怕，要求业界自律，呼吁政府管理，结果还真把一些官员吓住了。欧洲对基因工程研究管得非常严，美国则管得很松。结果导致在生物技术领域，美国大大领先欧洲。现在回头来看，基因工程技术已经发展到了相当高的程度，毁灭人类了吗？现在还有哪一个生物学家认为基因工程搞不好就会毁灭人类呢？几十年前的那种担忧，是不是很可笑呢？
2023.05.31录制
2023.07.26整理
(XYS20230805) "><meta name=og:image content="https://project-gutenberg.github.io/Pincong//images/card/14.jpg"><script data-ad-client=ca-pub-6074407261372769 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-06HJ1E5XNH"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-06HJ1E5XNH')</script></head><body><header class="fixed-top navigation"><div class=container><nav class="navbar navbar-expand-lg navbar-light bg-transparent"><a class=navbar-brand href=https://project-gutenberg.github.io/Pincong/><img class=img-fluid src=https://project-gutenberg.github.io/Pincong//images/logo.png alt=品葱*精选></a>
<button class="navbar-toggler border-0" type=button data-toggle=collapse data-target=#navigation>
<i class="ti-menu h3"></i></button><div class="collapse navbar-collapse text-center" id=navigation><ul class="navbar-nav ml-auto"><li class=nav-item><a class=nav-link href=https://project-gutenberg.github.io/Pincong/>Home</a></li><li class=nav-item><a class=nav-link href=https://project-gutenberg.github.io/Pincong/post/index.xml>RSS</a></li><li class=nav-item><a class=nav-link href=https://bit.ly/2HrxEi0>Telegram</a></li><li class=nav-item><a class=nav-link href=https://twitter.com/speechfree3>Twitter</a></li></ul></div></nav></div></header><div class="py-5 d-none d-lg-block"></div><section class=main-content><div class=container><div class=row><div class="col-lg-8 mx-auto block shadow mb-5"><h2>人工智能能有多可怕？</h2><div class=mb-3><span>by <a href=https://project-gutenberg.github.io/Pincong/author/%e6%96%b9%e8%88%9f%e5%ad%90>方舟子</a></span>,
<span>at 12 August 2023</span>, tags :
<a href=https://project-gutenberg.github.io/Pincong/tags/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd>人工智能</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e7%a0%94%e5%8f%91>研发</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e7%81%ad%e7%bb%9d>灭绝</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e7%ad%be%e5%90%8d>签名</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e4%ba%ba%e7%b1%bb>人类</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e6%96%b0%e8%af%ad%e4%b8%9d>新语丝</a>
<a href=https://github.com/Project-Gutenberg/Pincong-data/edit/master/site/content/post/f22e4f5dbce41aefc8aa4b7faa6df950.md style=color:gray><strong><i>点击纠错</i></strong></a>
<i></i><a href=https://github.com/Project-Gutenberg/Pincong-data/delete/master/site/content/post/f22e4f5dbce41aefc8aa4b7faa6df950.md style=color:gray><strong><i>点击删除</i></strong></a></div><h5><a href=https://bit.ly/justmysock>使用CN2/CN2GIA顶级线路，支持Shadowsocks/V2ray科学上网，支持支付宝付款，每月仅需 5 美元</a></h5><h5><a href=https://bit.ly/2HrxEi0>## 加入品葱精选 Telegram Channel ##</a></h5><p></p><p>人工智能能有多可怕？</p><p>·方舟子·</p><p>一批研发人工智能的科学家、工程师、业界领袖联合发表声明，警告人们：人工智能有造成灭绝人类的风险。这个声明是放在网上征集签名的，签名的人数会越来越多，现在已有300多人签名。其中包括研发出ChatGPT的OpenAI公司老总、谷歌研发人工智能的DeepMind公司老总，以及两个因研究人工智能获得图灵奖（计算机科学领域的最高奖）的科学家。这个声明很简单，只有一句话：减轻人工智能可能带来的灭绝风险要成为全球优先做的事情，就像对待其他社会级别的风险，例如瘟疫大流行和核武器一样。为什么只有一句话呢？据组织签名的人说，因为这更容易有共识。</p><p>人工智能有可能灭绝人类并不是什么新的想法，很早以前就有了。几年前，谷歌研发的AlphaGo打败了李世石，当时就有人说，人工智能再这么搞下去，会变得智力非常高超，会因此把人类消灭了。我当时就说这是危言耸听，是科幻小说、科幻电影看多了。</p><p>有人可能会说，你不是搞人工智能的专家，在这方面有什么发言权？难道你比那三百多个研发人工智能的专家、权威对这个问题更懂吗？</p><p>人工智能会不会毁灭人类不是一个技术问题，而是一个哲学问题，不需要是人工智能领域的专家也可以对这个问题进行讨论、发表见解。今年三月份，也有一千多人联合发表了一篇声明警告人们，人工智能很危险，呼吁研发人工智能的人暂时停止研发6个月。这一千多人并不都是搞人工智能的，实际上绝大部分不是搞人工智能的，他们也签名了。例如马斯克本身并不搞人工智能，未必懂人工智能，但也签名了。可见对这个问题，不是该领域的专家、权威也有发言权。</p><p>而且，关于人工智能会不会灭绝人类，在人工智能领域并没有形成共识。虽然签名的人数有三百多，听上去好像很多，但人工智能是一个非常热门的领域，研发的人非常多，专家、权威也非常多，这三百多人只是其中的一小部分而已。那些研发人工智能的公司并没有都签名，例如脸书下面研发人工智能的公司就没有签名。因研究人工智能获得图灵奖的科学家也并没有都签名。所以这并不是人工智能业界的共识。</p><p>这些研发人工智能的人出来警告人们，人工智能有灭绝人类的风险，让人觉得很蹊跷，动机很可疑。他们本身就在研发人工智能，而且是这个领域的领军人物，为什么却要人们警惕人工智能的危险，甚至是灭绝人类这么吓人的危险？他们为什么还要明知故犯去研究一个有可能灭绝人类的、如此恐怖的技术呢？这一方面是要显得自己很自律，站在道德高位；另一方面是希望政府把这个领域管起来。政府的管理对这些领先的公司、人物影响不会太大，对那些黑马影响更大，而这些领先公司、人物就可以一直保持领先的地位。社交媒体领域最大的公司脸书一直在呼吁美国政府把社交媒体管起来，也是同样的理由，一方面显得自己很高尚，另一方面，这个领域真的被管起来，会对别的社交媒体造成更大的负面影响，对已经领先、有着优势地位的公司影响不会很大。</p><p>所以，这么呼吁的人其实是言不由衷的，是别有用心的。如果他们真的认为人工智能这么可怕，那么在政府管理之前，他们就应该首先自律，暂停人工智能的研究，就像三月份那1000多个人发的声明里说的，暂停研究人工智能6个月。但三月份发声明的1000多人中也有一部分是研发人工智能的，或者本身不研发但投资人工智能的。比如马斯克，本身不懂人工智能、不研发人工智能，但他投资了至少两家人工智能公司。但是他虽然参与签名呼吁暂停研究6个月，自己投资的公司却没有暂停。这些研发、投资人工智能的，继续在研发、投资人工智能，丝毫没有停下来的迹象，反而竞争更加激烈。发这样的声明是不是显得很虚伪？</p><p>人工智能是一项技术，跟其他技术一样，如果被滥用，当然会带来一定的社会问题，造成一定的风险。目前面临着的最大问题是人工智能被用于制造、散布虚假信息。ChatGPT现在非常火，很多人都在使用，但也有很多人不知道ChatGPT提供的信息并不都是准确的，经常会胡编乱造、以假乱真。最近在美国就有一个例子。一个律师使用ChatGPT写答辩词，交给法庭后被法官发现他引用的6个案例都是假的，是ChatGPT胡编出来的。而且，现在用人工智能来制造假照片、假视频已经达到足以乱真的地步，人们识别起来非常麻烦。这个问题会变得越来越严重，是应该重视的。</p><p>其次，人工智能的发展会导致一些行业过时，会有相当多的人要失业、转行。这并不是一个新的问题。很多技术的发明、发展都会带来同样的问题，都会导致一些行业消失，很多人失业、转行，人工智能并不是一个例外。还有，人工智能以后有可能被用于帮助研发武器，比如生物武器、化学武器，导致这些武器杀伤力非常强。这是不是说明人工智能会毁灭人类呢？人工智能在这方面只是一个工具而已。研发生物武器、化学武器还要用到别的技术，那么是不是说明这些技术也会导致人类灭绝呢？其实，研发这种能导致人类灭绝的大规模杀伤武器，都是邪恶政权干的，再怎样立法、管理，对他们来说都是不起作用的。而且，早就有灭绝人类的技术了，核武器技术已经有了，没有必要等到人工智能达到多高的程度才会导致人类灭绝。</p><p>对于人工智能有可能带来的社会问题，当然要正视，并不是说不存在。我们反对的是危言耸听，把它说得特别严重。这让我想起上世纪七十年代，基因工程刚刚发明，也有一些生物学家把基因工程想象得特别可怕，要求业界自律，呼吁政府管理，结果还真把一些官员吓住了。欧洲对基因工程研究管得非常严，美国则管得很松。结果导致在生物技术领域，美国大大领先欧洲。现在回头来看，基因工程技术已经发展到了相当高的程度，毁灭人类了吗？现在还有哪一个生物学家认为基因工程搞不好就会毁灭人类呢？几十年前的那种担忧，是不是很可笑呢？</p><p>2023.05.31录制</p><p>2023.07.26整理</p><p>(XYS20230805)</p><h5><a href="https://www.digitalocean.com/?refcode=4351d40e44b2&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=CopyPaste">最简单好用的 VPS,没有之一，注册立得 100 美金</a></h5></div><div class="col-lg-8 mx-auto block shadow"><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var t=document,e=t.createElement('script');e.async=!0,e.src='//pin-cong-jing-xuan.disqus.com/embed.js',e.setAttribute('data-timestamp',+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><div class="col-lg-8 mx-auto block shadow"><h3>See Also</h3><div class=container><div class=row><div class="mx-auto px-0"><div class="bg-white shadow block"><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/ab0e33fa8e0757554b77dd75ff8f7362/?utm_source=see_also&utm_medium=%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BD%25E8%2583%25BD%25E6%259C%2589%25E5%25A4%259A%25E5%258F%25AF%25E6%2580%2595">GTP-4来了，“奇点将至”对我们会有多么致命</a></h2><p class=text-dark>收录于合集 #那个文明从这里走过 44个
科技的发展不是“匀速”的，
它给不同人群带来的影响，也不会是“匀质”的。
先讲一个历史段子。
一百多年前的甲午海战中，北洋水师大败亏输，间接导致大清在于日本国运对赌当中战败。甲午海战的北洋水师战败的 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/eea7f15e60ed39e12c42ccbc0f0fb10d/?utm_source=see_also&utm_medium=%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BD%25E8%2583%25BD%25E6%259C%2589%25E5%25A4%259A%25E5%258F%25AF%25E6%2580%2595">人工智能或将取代医生的几个理由</a></h2><p class=text-dark>人工智能或将取代医生的几个理由
作者：李长青
人工智能已经取代了一些人的工作，包括以前被认为高大上，足以养家糊口甚至飞黄腾达的职业。未来很可能还会取代更多的职业。每个人都免不了心里嘀咕，自己会不会是被取消的那一种。作为医生，也免不了担心。面 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/355ffa1a264b7bc09804d1994ef5dd2a/?utm_source=see_also&utm_medium=%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BD%25E8%2583%25BD%25E6%259C%2589%25E5%25A4%259A%25E5%258F%25AF%25E6%2580%2595">人工智能真正的恐怖之处</a></h2><p class=text-dark>人工智能真正的恐怖之处
作者：EZRA KLEIN　2023年2月27日纽约时报
2021年，我采访了当世最杰出的科幻作家之一姜峯楠。他当时说的一些话，我如今时常会记起。
“我倾向于认为，将大部分人工智能恐惧解读为资本主义恐惧最为恰当，”姜 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/2c3cc5151c0d94c74bcf3ed4d034ec37/?utm_source=see_also&utm_medium=%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BD%25E8%2583%25BD%25E6%259C%2589%25E5%25A4%259A%25E5%258F%25AF%25E6%2580%2595">如果有一种病毒，所有的口罩都防不住他，有 90％至 100％的致死率，人类会不会灭绝？</a></h2><p class=text-dark>知乎用户 骷髅森 发表 玩过瘟疫公司的人都知道，不能太早点致死
……
兄弟萌，点错了，不是死早了影响传播，而是死人很容易让人重视起来，造疫苗啥的，病毒再猛，也是蛋白质和遗传物质组成的。
知乎用户 赵泠​​ 发表 狂犬病毒，主要传播方式无视口 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/baf181cf1654d8be3d176a90c964bdef/?utm_source=see_also&utm_medium=%25E4%25BA%25BA%25E5%25B7%25A5%25E6%2599%25BA%25E8%2583%25BD%25E8%2583%25BD%25E6%259C%2589%25E5%25A4%259A%25E5%258F%25AF%25E6%2580%2595">为什么 00 后（特别是女生）都不想生孩子啊？</a></h2><p class=text-dark>知乎用户 匿名用户 发表 厚！
是我想来到这个世界上的嘛？
是我想成为人类的嘛？
我秉承着 “来都来了” 的人生态度活着。
你问我人类灭绝了怎么办？
关我 piss 啦
关你 piss 啦
人类灭绝了地球母亲笑的比我都开心。
知乎用户 瑜小 …</p></article></div></div></div></div></div></div></div></div></section><script>var i,images=document.getElementsByTagName("img");for(i=0;i<images.length;i++)images[i].className+="img-fluid w-100 mb-4"</script><footer class="py-4 bg-light border-top"><div class=container><div class="row justify-content-between align-items-center"><div class="col-lg-4 text-center text-lg-left mb-4 mb-lg-0"><a href=https://project-gutenberg.github.io/Pincong/><img src=https://project-gutenberg.github.io/Pincong//images/logo.png class=img-fluid alt=品葱*精选></a></div><div class="col-lg-4 text-center mb-4 mb-lg-0"><ul class="list-inline mb-0"></ul></div><div class="col-lg-4 text-lg-right text-center mb-4 mb-lg-0"><ul class="list-inline social-icon mb-0"><li class=list-inline-item><a href=https://pincong.rocks/><i class=ti-home></i></a></li><li class=list-inline-item><a href=https://github.com/Project-Gutenberg/Pincong><i class=ti-github></i></a></li></ul></div><div class="col-12 text-center mt-4"><span></span></div></div></div></footer><script src=../../plugins/jQuery/jquery.min.js></script>
<script src=../../plugins/bootstrap/bootstrap.min.js></script>
<script src=../../plugins/search/fuse.min.js></script>
<script src=../../plugins/search/mark.js></script>
<script src=../../plugins/search/search.js></script>
<script src=https://project-gutenberg.github.io/Pincong/js/script.min.js></script>
<script>(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)})(window,document,'script','//www.google-analytics.com/analytics.js','ga'),ga('create','UA-151212685-6','auto'),ga('send','pageview')</script></body></html>