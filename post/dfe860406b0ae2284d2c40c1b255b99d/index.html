<!doctype html><html lang=zh-cn><head><meta charset=utf-8><title>手机拍照自动抠图、秒变PS素材：华人团队技术实现一键“剪切现实”</title><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content=" 解释最新科技进展，报道硅谷大事小情
点击上方“硅星人”关注我们~
现实里抠图，随手放到PS里？真实和虚拟之间又一堵墙被打破了，而华人团队是幕后功臣。
——
文｜杜晨 编辑｜Vicky Xiao
最近，一段模糊了虚拟和现实边界的黑科技视频在 Twitter 上爆红，目前已经获得了数万点赞和转推。
视频中，开发者 Cyril Diagne 用自己的手机拍下身边的绿枝、书本、衣服等物体，手机立刻把物体从画面中抠了出来。
接下来发生的事情更加神奇：他把手机摄像头对准电脑的屏幕，刚才抠出来的物体，竟然自动添加到了电脑正在运行的 Photoshop 上！
几秒钟前还在现实中的物体，竟然就这么被复制到了虚拟的世界里。
可能令许多摄影师、设计师朋友感到嫉妒的是，Diagne 的这一通操作是完全自动化的，并没有用到数据线，没碰键盘，也没用鼠标做任何调整——剪贴进去的图像，就这么准确地出现在他用手机瞄准的画面位置上。
Diagne 将这套非常神奇的抠图技术命名为 AR Cut & Paste（增强现实剪切粘贴）。目前针对 Photoshop 的支持已经开发出来了，不过他也表示其它软件也是可以支持的。
他也把 AR Cut & Paste 放到 GitHub 上开源了。从介绍和代码中我们得以一窥，这么有趣的技术，到底是怎么实现的。
秘诀：华人团队开发的图像识别模型
在抠图的阶段，AR Cut & Paste 使用的是一个名叫 BASNet 的深度神经网络。
在过去，机器学习领域在利用深度卷积神经网络进行物体识别方面，已经取得了非常不错的结果。不过通过神经网络进行的图像中物体识别，主要目标是区域准确性，而非边界准确性。
简单来说，就是这些物体识别技术，能够很准确地答出画面中的物体分别是什么：
但是想要准确画出识别出的物体的边框，就很难：
于是，加拿大阿尔伯塔大学的一个以华人为主的团队，开发出了一个全新的深度神经网络模型。
BASNet 的主要功能是进行显著性检测，简单来说，就是对画面中最显著的物体实现准确的边界划定，效果就像 PS 高手人工“抠图”一样。 "><meta name=generator content="Hugo 0.100.2"><link rel=stylesheet href=../../plugins/bootstrap/bootstrap.min.css><link rel=stylesheet href=../../plugins/themify-icons/themify-icons.css><link rel=stylesheet href=https://project-gutenberg.github.io/Pincong/scss/style.min.css media=screen><link rel="shortcut icon" href=https://project-gutenberg.github.io/Pincong/images/favicon.png type=image/x-icon><link rel=icon href=https://project-gutenberg.github.io/Pincong/images/favicon.png type=image/x-icon><meta name=twitter:card content="summary_large_image"><meta name=og:title content=" 手机拍照自动抠图、秒变PS素材：华人团队技术实现一键“剪切现实” "><meta name=og:description content=" 解释最新科技进展，报道硅谷大事小情
点击上方“硅星人”关注我们~
现实里抠图，随手放到PS里？真实和虚拟之间又一堵墙被打破了，而华人团队是幕后功臣。
——
文｜杜晨 编辑｜Vicky Xiao
最近，一段模糊了虚拟和现实边界的黑科技视频在 Twitter 上爆红，目前已经获得了数万点赞和转推。
视频中，开发者 Cyril Diagne 用自己的手机拍下身边的绿枝、书本、衣服等物体，手机立刻把物体从画面中抠了出来。
接下来发生的事情更加神奇：他把手机摄像头对准电脑的屏幕，刚才抠出来的物体，竟然自动添加到了电脑正在运行的 Photoshop 上！
几秒钟前还在现实中的物体，竟然就这么被复制到了虚拟的世界里。
可能令许多摄影师、设计师朋友感到嫉妒的是，Diagne 的这一通操作是完全自动化的，并没有用到数据线，没碰键盘，也没用鼠标做任何调整——剪贴进去的图像，就这么准确地出现在他用手机瞄准的画面位置上。
Diagne 将这套非常神奇的抠图技术命名为 AR Cut & Paste（增强现实剪切粘贴）。目前针对 Photoshop 的支持已经开发出来了，不过他也表示其它软件也是可以支持的。
他也把 AR Cut & Paste 放到 GitHub 上开源了。从介绍和代码中我们得以一窥，这么有趣的技术，到底是怎么实现的。
秘诀：华人团队开发的图像识别模型
在抠图的阶段，AR Cut & Paste 使用的是一个名叫 BASNet 的深度神经网络。
在过去，机器学习领域在利用深度卷积神经网络进行物体识别方面，已经取得了非常不错的结果。不过通过神经网络进行的图像中物体识别，主要目标是区域准确性，而非边界准确性。
简单来说，就是这些物体识别技术，能够很准确地答出画面中的物体分别是什么：
但是想要准确画出识别出的物体的边框，就很难：
于是，加拿大阿尔伯塔大学的一个以华人为主的团队，开发出了一个全新的深度神经网络模型。
BASNet 的主要功能是进行显著性检测，简单来说，就是对画面中最显著的物体实现准确的边界划定，效果就像 PS 高手人工“抠图”一样。 "><meta name=og:image content="https://project-gutenberg.github.io/Pincong//images/card/80.jpg"><script data-ad-client=ca-pub-6074407261372769 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-06HJ1E5XNH"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-06HJ1E5XNH')</script></head><body><header class="fixed-top navigation"><div class=container><nav class="navbar navbar-expand-lg navbar-light bg-transparent"><a class=navbar-brand href=https://project-gutenberg.github.io/Pincong/><img class=img-fluid src=https://project-gutenberg.github.io/Pincong//images/logo.png alt=品葱*精选></a>
<button class="navbar-toggler border-0" type=button data-toggle=collapse data-target=#navigation>
<i class="ti-menu h3"></i></button><div class="collapse navbar-collapse text-center" id=navigation><ul class="navbar-nav ml-auto"><li class=nav-item><a class=nav-link href=https://project-gutenberg.github.io/Pincong/>Home</a></li><li class=nav-item><a class=nav-link href=https://project-gutenberg.github.io/Pincong/post/index.xml>RSS</a></li><li class=nav-item><a class=nav-link href=https://bit.ly/2HrxEi0>Telegram</a></li><li class=nav-item><a class=nav-link href=https://twitter.com/speechfree3>Twitter</a></li></ul></div></nav></div></header><div class="py-5 d-none d-lg-block"></div><section class=main-content><div class=container><div class=row><div class="col-lg-8 mx-auto block shadow mb-5"><h2>手机拍照自动抠图、秒变PS素材：华人团队技术实现一键“剪切现实”</h2><div class=mb-3><span>by <a href=https://project-gutenberg.github.io/Pincong/author/%e5%85%89%e8%b0%b1nbsp%e6%9d%9c%e6%99%a8>光谱&amp;Nbsp;杜晨</a></span>,
<span>at 12 May 2020</span>, tags :
<a href=https://project-gutenberg.github.io/Pincong/tags/%e7%89%a9%e4%bd%93>物体</a>
<a href=https://github.com/Project-Gutenberg/Pincong-data/edit/master/site/content/post/dfe860406b0ae2284d2c40c1b255b99d.md style=color:gray><strong><i>点击纠错</i></strong></a>
<i></i><a href=https://github.com/Project-Gutenberg/Pincong-data/delete/master/site/content/post/dfe860406b0ae2284d2c40c1b255b99d.md style=color:gray><strong><i>点击删除</i></strong></a></div><h5><a href=https://bit.ly/justmysock>使用CN2/CN2GIA顶级线路，支持Shadowsocks/V2ray科学上网，支持支付宝付款，每月仅需 5 美元</a></h5><h5><a href=https://bit.ly/2HrxEi0>## 加入品葱精选 Telegram Channel ##</a></h5><p></p><p>解释最新科技进展，报道硅谷大事小情</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_gif/cn2WtQ1Q5KSaAibwHE1Y48uXsicqOmbWWEVszeKVkTLSmOoZRM1Vjwtrxo0PQeS4WfWFXwMNsrO5tVkicVuUWx0Uw/640%3Fwx_fmt%3Dgif" alt></p><p>点击上方“硅星人”关注我们~</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KTGjRWPaoVEjRAbyIXzBFLdILVnJ4U2QyicibSiaAAliccaN6iapia8gasxUjhXE4wmKdgVcBhcX6SGG09g/640%3Fwx_fmt%3Djpeg" alt></p><p>现实里抠图，随手放到PS里？真实和虚拟之间又一堵墙被打破了，而华人团队是幕后功臣。</p><p>——</p><p>文｜杜晨    编辑｜Vicky Xiao</p><p>最近，一段模糊了虚拟和现实边界的黑科技视频在 Twitter 上爆红，目前已经获得了数万点赞和转推。</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_gif/cn2WtQ1Q5KTGjRWPaoVEjRAbyIXzBFLd0CBic0dzunMibsWE8kicHsavI5Tpg62yWsd2iaibEUWSQAnO7O2TerMZOMQ/640%3Fwx_fmt%3Dgif" alt></p><p>视频中，开发者 Cyril Diagne 用自己的手机拍下身边的绿枝、书本、衣服等物体，手机立刻把物体从画面中抠了出来。</p><p>接下来发生的事情更加神奇：<strong>他把手机摄像头对准电脑的屏幕，刚才抠出来的物体，竟然自动添加到了电脑正在运行的 Photoshop 上！</strong></p><p>几秒钟前还在现实中的物体，竟然就这么被复制到了虚拟的世界里。</p><p>可能令许多摄影师、设计师朋友感到嫉妒的是，Diagne 的这一通操作是完全自动化的，并没有用到数据线，没碰键盘，也没用鼠标做任何调整——剪贴进去的图像，就这么准确地出现在他用手机瞄准的画面位置上。</p><p>Diagne 将这套非常神奇的抠图技术命名为 AR Cut & Paste（增强现实剪切粘贴）。目前针对 Photoshop 的支持已经开发出来了，不过他也表示其它软件也是可以支持的。</p><p>他也把 AR Cut & Paste 放到 GitHub 上开源了。从介绍和代码中我们得以一窥，这么有趣的技术，到底是怎么实现的。</p><p>秘诀：华人团队开发的图像识别模型</p><p>在抠图的阶段，AR Cut & Paste 使用的是一个名叫 <strong>BASNet</strong> 的深度神经网络。</p><p>在过去，机器学习领域在利用深度卷积神经网络进行物体识别方面，已经取得了非常不错的结果。不过通过神经网络进行的图像中物体识别，主要目标是区域准确性，而非边界准确性。</p><p>简单来说，就是这些物体识别技术，能够很准确地答出画面中的物体分别是什么：</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KTGjRWPaoVEjRAbyIXzBFLdRpRvwYIyqib2oY9NKRpjLliaZJHGvf4y0BKC3oP3IKSYHAtYXEM5fcNw/640%3Fwx_fmt%3Djpeg" alt></p><p>但是想要准确画出识别出的物体的边框，就很难：</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/cn2WtQ1Q5KTGjRWPaoVEjRAbyIXzBFLdvxfZNMTagBOhrpcz5IOcfW91HzWjtOKGWAQ6ricCzEkOYz3tG7dlAMA/640%3Fwx_fmt%3Dpng" alt></p><p>于是，加拿大阿尔伯塔大学的一个以华人为主的团队，开发出了一个全新的深度神经网络模型。</p><p>BASNet 的主要功能是进行显著性检测，简单来说，就是对画面中最显著的物体实现准确的边界划定，效果就像 PS 高手人工“抠图”一样。</p><p>BASNet 采用了预测-优化的思路，主要使用的是 Encoder-Decoder 网络结构，底层采用的是微软团队开发的残差网络 ResNet。</p><p>在预测部分，一个密集监督的 Encoder-Decoder 网络负责预测预测画面中物体的显著性，借助三种不同损失函数，让神经网络可以在像素 (pixel)、像素区域 (patch) 和全图 (map) 这三个层级上进行显著性判定，从而输出更准确的结果。</p><p>在优化部分，仍然是由 Encoder-Decoder 结构组装成一个残差优化模块 (RRM) ，对预测部分输出的显著图进一步优化。</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KTGjRWPaoVEjRAbyIXzBFLdJaZ1jicicqUCD2cNU0ianwNibAxbp3E3XgUPRaY0btx1FhfQDrfh2DJnEw/640%3Fwx_fmt%3Djpeg" alt></p><p>从下图中可以看到，和其它同类和类似的物体识别模型相比，BASNet 的边界划定效果相对更加准确，和手动画出的标准答案最为接近。</p><p>不仅如此，BASNet 对于计算性能的优化做的也不错，可以在单一 GPU 上运行达到25帧每秒（需要你的电脑上有支持 CUDA 的 GPU）。</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KTGjRWPaoVEjRAbyIXzBFLd8fOAYGERuk5hCIt95IibtZicDUzOEgPpccRU81SbKrxlicO6PzJkuNvcg/640%3Fwx_fmt%3Djpeg" alt></p><p>这篇论文在去年被计算机视觉方面的顶级学术会议 CVPR 2019 所收录。</p><p>BASNet 的开发团队来自于加拿大的阿尔伯塔大学计算机系。第一作者是该校机器人和视觉实验室的秦雪彬博士，曾经就读于山东农业大学和北京大学。</p><p>从网站上也能够很清楚地看出，在各种图像视频中进行物体显著性/边界划定，是秦雪彬最拿得出手的研究：</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/cn2WtQ1Q5KTGjRWPaoVEjRAbyIXzBFLdKhfhhH6eST3FohVdkd2ibUXevbDMrmGmicicPXs8QYcfibGLBrB3oBxYNQ/640%3Fwx_fmt%3Dpng" alt></p><p>秦的团队还推出了一个性能更加强大的模型 U^2-Net，对于复杂物体边缘的识别准确度再上新台阶。这篇新论文目前已经被《模式识别》2020年收录。</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/cn2WtQ1Q5KTGjRWPaoVEjRAbyIXzBFLdoQ7lVbwTWWIKwesI82hrxZ1exJfPAGYAy37NnI9nTqMRYZ6dDb9Dvg/640%3Fwx_fmt%3Dpng" alt></p><p>现在我们知道了，AR Cut & Paste 是借助了 BASNet 这一深度神经网络实现了较为准确的抠图。接下来，开发者 Diagne 又是怎么实现将抠出来的图片直接隔空从手机“放置”到电脑上，而且准确放在手机瞄准位置的呢？</p><p>这里，Diagne 用了自己开发的一个小的玩意 ScreenPoint，简单来说就是在一张照片（手机传回的画面）上确定一个锚点，然后在对应的另一张照片（电脑的画面）上找到锚点对应的坐标。</p><p>这个小工具，利用的是 OpenCV 的 SIFT 功能。</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/cn2WtQ1Q5KTGjRWPaoVEjRAbyIXzBFLdfpBXp1gP6hCyzxDU3sFUdzeHMu608klea660ghkDpUHnqG5jjcNCew/640%3Fwx_fmt%3Dpng" alt></p><p>目前，AR Cut & Paste 在剪切阶段的延迟大约为2.5秒，粘贴的延迟约为4秒。Diagne 也在 Twitter 上表示，还有很多方法能够进一步降低延迟，不过他并没有花更多时间做核心功能之外的优化。</p><p>技术实现的逻辑听上去并没有特别复杂，不过感谢强大的 BASNet，加上 Diagne 的脑洞，AR Cut & Paste 的实际使用效果还是很神奇的——特别是对于那些每天跟套索打交道的 Photoshop 用户来说……</p><p>AR Cut & Paste 上手配置</p><p>看到这里，相信你也已经按耐不住，想要自己上手玩一玩这套 AR Cut & Paste 了。</p><p>Diagne 在自己的 GitHub 提供了你需要的全部代码和一份简单的使用说明书。点击文章下方的“阅读原文”即可看到。</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/cn2WtQ1Q5KTGjRWPaoVEjRAbyIXzBFLd5SuxolWcqpnH9KM8orEqYXkWZUdDljBqHESbXbODqqftiaeibMDkicN7Q/640%3Fwx_fmt%3Dpng" alt></p><p>总的来说，AR Cut & Paste 有三个独立的模块，需要配合使用：<strong>手机 app、安装在电脑上的本地服务器，以及打包好的 BASNet HTTP 服务。</strong></p><p>手机是你的交互工具；本地服务器是手机和 Photoshop 之间数据传输的界面；物体检测、边界划定和背景移除的操作，发生在 BASNet HTTP 服务上。</p><p>在你的本地配置 AR Cut & Paste 需要一台手机，一台 GPU 支持 CUDA 的电脑；配置过程需要你有一定的 React Native 移动应用开发支持，电脑上有 Python 或 Docker 开发环境等。</p><p>1</p><p>配置 Photoshop 插件远程连接</p><p>进入 Photoshop 的偏好设置 (Preference) > 插件 (Plug-ins)，打开远程连接 (Remote Connection)，并设置一个密码。</p><p>然后在 GitHub Repo 里找到 cyrildiagne/ar-cutpaste/server/src/ps.py，确认你的 Photoshop 设置和这个文件里是一样的，否则粘贴出来的会是一个空白的图层。</p><p>2</p><p>打包 BASNet HTTP 服务</p><p>先克隆 cyrildiagne/basnet-http：</p><pre><code>git clone https:
</code></pre><p>进入这个 repo，再把阿尔伯塔大学团队的 BASNet 克隆进去。</p><pre><code>git clone https:
</code></pre><p>然后下载训练好的 BASNet 模型文件 basnet.pth（shorturl.at/FVZ19，下载地址也可以在 BASNet HTTP 打包工具的 GitHub 页面上找到），放到BASNet/saved_models/basnet_bsi/ 路径下。</p><p>3</p><p>配置本地服务器</p><p>然后就可以开始构建服务了，可以在本地使用 Python 运行环境 virtualenv（需要Python v3.6 或以上），也可以使用 Docker，具体操作方法在 GitHub 上都有。</p><p>然后就可以运行了服务器了，记得要输入打包好的 BASNet HTTP 服务的IP地址 (X.X.X.X)，和之前第一步在 Photoshop 里设定的远程连接密码 (123456)：</p><pre><code>python src/main.py \
</code></pre><p>4</p><p>配置手机端</p><p>手机客户端是 Diagne 自己用 React Native 开发的 app。下载代码，安装，将手机端 components/Server.txt 文件里的 IP 地址指向到前一步配置的本地服务器和对应的端口即可，具体请参考 GitHub。</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/cn2WtQ1Q5KTGjRWPaoVEjRAbyIXzBFLdkm3iaHaicdzc6n2DDSMRq0R23QN91EIH4qpwUPS4w9DJuy3SUuWmEWDw/640%3Fwx_fmt%3Dpng" alt></p><p>需要强调的是，目前 AR Cut & Paste 只是一个研究性质的原形产品，并非面向消费者的和 Photoshop 工具，所以使用须谨慎，以免不必要的 Photoshop 资料丢失。</p><p>怎么样，你是不是已经跃跃欲试了呢？赶快行动起来吧！</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/cn2WtQ1Q5KSaAibwHE1Y48uXsicqOmbWWEKEZknqxMIqEGuOAKqiaQ0GAicbKfcxUCJibicvcBzRoH0CP29EHADIjLUA/640%3Fwx_fmt%3Dpng" alt></p><p><strong>喜欢这篇文章？</strong></p><p><strong>1）点击右下角的“在看”</strong></p><p><strong>2）分享到你的朋友圈和群里</strong></p><p><strong>3）赶快关注硅星人吧！</strong></p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/cn2WtQ1Q5KTjx9juhZk9WPSllLiaC5vBicRtmaOrnCotPWjGJc6oGNkX0dxbZDmWegHfD1icESicIK4UeDD0w31XDA/640%3Fwx_fmt%3Dpng" alt></p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KTjx9juhZk9WPSllLiaC5vBicwzhpDG8f4ZZ4nPGRODGVKgnj2Sy3MasUjFQtyJ89CrYmApfnHO4mZw/640%3Fwx_fmt%3Djpeg" alt></p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/cn2WtQ1Q5KTjx9juhZk9WPSllLiaC5vBicfUJSQmXfkDib2Wv0QcMjQLMnppOd0ppWwZlFwLQ1Tqr4ToPXTImNTrQ/640%3Fwx_fmt%3Dpng" alt></p><p>关注硅星人，你就能了解硅谷最新的科技进展和湾区的大事小情，变身最in技术潮人</p><p>光谱 杜晨</p><p>长按二维码向我转账</p><p>受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p><p>文章已于修改</p><h5><a href="https://www.digitalocean.com/?refcode=4351d40e44b2&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=CopyPaste">最简单好用的 VPS,没有之一，注册立得 100 美金</a></h5></div><div class="col-lg-8 mx-auto block shadow"><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var t=document,e=t.createElement('script');e.async=!0,e.src='//pin-cong-jing-xuan.disqus.com/embed.js',e.setAttribute('data-timestamp',+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><div class="col-lg-8 mx-auto block shadow"><h3>See Also</h3><div class=container><div class=row><div class="mx-auto px-0"><div class="bg-white shadow block"></div></div></div></div></div></div></div></div></section><script>var i,images=document.getElementsByTagName("img");for(i=0;i<images.length;i++)images[i].className+="img-fluid w-100 mb-4"</script><footer class="py-4 bg-light border-top"><div class=container><div class="row justify-content-between align-items-center"><div class="col-lg-4 text-center text-lg-left mb-4 mb-lg-0"><a href=https://project-gutenberg.github.io/Pincong/><img src=https://project-gutenberg.github.io/Pincong//images/logo.png class=img-fluid alt=品葱*精选></a></div><div class="col-lg-4 text-center mb-4 mb-lg-0"><ul class="list-inline mb-0"></ul></div><div class="col-lg-4 text-lg-right text-center mb-4 mb-lg-0"><ul class="list-inline social-icon mb-0"><li class=list-inline-item><a href=https://pincong.rocks/><i class=ti-home></i></a></li><li class=list-inline-item><a href=https://github.com/Project-Gutenberg/Pincong><i class=ti-github></i></a></li></ul></div><div class="col-12 text-center mt-4"><span></span></div></div></div></footer><script src=../../plugins/jQuery/jquery.min.js></script>
<script src=../../plugins/bootstrap/bootstrap.min.js></script>
<script src=../../plugins/search/fuse.min.js></script>
<script src=../../plugins/search/mark.js></script>
<script src=../../plugins/search/search.js></script>
<script src=https://project-gutenberg.github.io/Pincong/js/script.min.js></script>
<script>(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)})(window,document,'script','//www.google-analytics.com/analytics.js','ga'),ga('create','UA-151212685-6','auto'),ga('send','pageview')</script></body></html>