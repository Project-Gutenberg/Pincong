<!doctype html><html lang=zh-cn><head><meta charset=utf-8><title>AI毁灭人类的“末日概率”是多少</title><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content=" AI毁灭人类的“末日概率”是多少
作者：KEVIN ROOSE　2023年12月6日纽约时报
本文是“交易录峰会”(DealBook Summit)特别报道的一部分，该峰会得到了世界各地商业及政策领袖的参与。
AI公司Anthropic的首席执行官达里奥·阿莫代伊给出的数字是10%到25%之间。联邦贸易委员会主席丽娜·汗近日告诉我，她认为的数值是15%。上月担任了五分钟的OpenAI临时首席执行官的艾米特·席尔告诉我，他得出的数值游移在5%到50%之间。
我这里说的，当然就是p(末日)了，这是硅谷正在热议的一项令人毛骨悚然的新数据。
P(末日)——就是用数学的方式表达“末日的概率”——是一些人工智能研究者在表达他们认为AI有多大可能把我们杀光，或创造别的什么威胁人类生存的灾变。P(末日)高意味着你认为AI末日的可能性大，低意味着你认为我们有机会挺过去。
P(末日)曾经只是网络论坛上一帮AI技术宅之间心领神会的笑话，但随着去年ChatGPT点燃的AI热让人对AI的进步之快产生恐惧，近几个月这个词进入了主流。
它已经成了旧金山技术人士交谈时常用的开场白——也是AI文化里躲不开的一部分。今年我在两场业界活动上遇到陌生人问我的p(末日)是多少，就像在问洗手间怎么走一样随意。“几乎每一场晚餐谈话都会提起，”云数据平台Box首席执行官艾伦·勒维对我说。
P(末日)甚至在上月OpenAI事变中对扮演了一定的角色。席尔被任命为OpenAI临时负责人后，公司雇员之间开始转发他在近日一期博客上的言论，称他的p(末日)可能高达50%。一位讨论时在场的人士说，有员工担心他是个“末日论者”，由于认为这太过冒险，他可能会寻求延缓或限制他们的工作。（被罢免的OpenAI首席执行官萨姆·奥尔特曼最终恢复原职，因此这件事也就无关紧要了。）
当然，科幻迷很久以前就已经开始推想机器人篡夺世界的景象。但在去年ChatGPT推出后，这种威胁似乎显得更真切了。毕竟如果AI模型可以赢得艺术奖项，通过律师资格考试，那么距离劫难还能有多远？
AI行内人也在发出警告。去年从谷歌辞职的著名AI研究者杰弗里·辛顿开始警告AI的风险，他近日估计如果不施加有力的监管，AI在未来30年导致人类灭绝的可能性为10%。和辛顿一同被誉为“深度学习教父”的约书亚·本吉奥在接受采访时说，他认为发生AI大劫难的可能性大约在20%。
没人知道我们被AI杀死的概率是10%、20%还是85.2%。显然这个问题会引出更多的问题，比如：如果AI导致50%的人类死亡，还算“末日”吗？如果没有人死，但我们全都丢了工作，只能喝西北风呢？到底AI会如何接管世界呢？
但是p(末日)的重点不在于精确。它的目的是表明，在是乌托邦还是反乌托邦的问题上，一个人大致的立场如何，此外也是用模糊的经验论术语传达你在AI问题及其潜在影响上的关切程度。
这个术语似乎是十多年前在网络论坛LessWrong上出现的，那是一个理性主义哲学运动主题论坛。
LessWrong创始人是一位自学成才的AI研究者，名叫埃利泽·尤科夫斯基，他很早就产生了失控AI可能接管一切的想法，并就他设想的多种AI灾难场景撰文。（当时的AI连设置个厨房计时器都很勉强，因此风险显得十分遥远。）
后来成了AI世界最著名末日论者的尤科夫斯基告诉我，p(末日)这个词不是他提出的，不过他做了推广普及。（他还说，如果继续以现在的趋势发展，他的p(末日)是“有多高就多高”。）这个词后来被有效利他主义者们拿去用了，这个群体旨在通过逻辑推论得出有关公序良俗的理念。
我的猜测是，这个词最早是由身在波士顿的蒂姆·泰勒于2009年开始在LessWrong上使用的。泰勒在邮件往来中说到，他用这个词“指代末日出现的概率，同时又不需要详细阐明时间尺度或末日的定义。”
对一些人来说，谈论你的p(末日)无非就是在闲扯。然而在硅谷的一场激烈辩论中，它又成了一个重要的社交信号，辩论的一方认为AI发展过快，另一方认为应该更快。
Box首席执行官勒维属于较乐观的一方。他说他的p(末日)值很低——不是零，但“能多低就多低”——他认为我们能化解AI的巨大风险，避免最糟糕的结果。他担心的不是AI会杀死我们，而是监管者和立法者会利用这些可怕的末日预言，用来理直气壮地打压一个前景远大的年轻行业。
“如果在AI发展中过早开始关键的政策决断，是有可能出现过度干预的，”他说。
P(末日)的另一个问题是，在关乎存亡的问题上，乐观与悲观的界线是不明确的。比如，如果你预言AI有15%的可能杀死所有人类，你真的算AI乐观主义者？（换个说法：如果你认为你下一次乘坐飞机“只有”15%的几率机毁人亡，你会上飞机吗？）
研究AI风险的Open Philanthropy高级研究员阿杰亚·科特拉在p(末日)的问题上花了不少时间。她认为它作为一个简称可能是有用的——顺便一提，她的p(末日)是20%到30%之间——但同时也存在局限。首先p(末日)没有考虑到，AI相关破坏的可能性在很大程度上取决于我们打算如何治理它。
“我知道有些人的p(末日)超过90%了，这在一定程度上是因为他们认为企业和政府不会操心什么良好的安全实践和政策措施，”她对我说。“我也知道有些人的p(末日)不到5%，这部分是因为他们预计科学家和政策制定者会努力预防灾难的发生。”
换句话说，你可以把p(末日)当做某种墨迹测验——这个数据说的是AI，但说到底更多是在表明我们是怎么看待人类的，我们能不能在控制住风险的同时让强大的新技术为我们所用。
那么，你的p(末日)是多少？
Kevin Roose是《纽约时报》科技专栏作家和播客“Hard Fork”的主持人。点击查看更多关于他的信息。
翻译：杜然
(XYS20231210) "><meta name=generator content="Hugo 0.100.2"><link rel=stylesheet href=../../plugins/bootstrap/bootstrap.min.css><link rel=stylesheet href=../../plugins/themify-icons/themify-icons.css><link rel=stylesheet href=https://project-gutenberg.github.io/Pincong/scss/style.min.css media=screen><link rel="shortcut icon" href=https://project-gutenberg.github.io/Pincong/images/favicon.png type=image/x-icon><link rel=icon href=https://project-gutenberg.github.io/Pincong/images/favicon.png type=image/x-icon><meta name=twitter:card content="summary_large_image"><meta name=og:title content=" AI毁灭人类的“末日概率”是多少 "><meta name=og:description content=" AI毁灭人类的“末日概率”是多少
作者：KEVIN ROOSE　2023年12月6日纽约时报
本文是“交易录峰会”(DealBook Summit)特别报道的一部分，该峰会得到了世界各地商业及政策领袖的参与。
AI公司Anthropic的首席执行官达里奥·阿莫代伊给出的数字是10%到25%之间。联邦贸易委员会主席丽娜·汗近日告诉我，她认为的数值是15%。上月担任了五分钟的OpenAI临时首席执行官的艾米特·席尔告诉我，他得出的数值游移在5%到50%之间。
我这里说的，当然就是p(末日)了，这是硅谷正在热议的一项令人毛骨悚然的新数据。
P(末日)——就是用数学的方式表达“末日的概率”——是一些人工智能研究者在表达他们认为AI有多大可能把我们杀光，或创造别的什么威胁人类生存的灾变。P(末日)高意味着你认为AI末日的可能性大，低意味着你认为我们有机会挺过去。
P(末日)曾经只是网络论坛上一帮AI技术宅之间心领神会的笑话，但随着去年ChatGPT点燃的AI热让人对AI的进步之快产生恐惧，近几个月这个词进入了主流。
它已经成了旧金山技术人士交谈时常用的开场白——也是AI文化里躲不开的一部分。今年我在两场业界活动上遇到陌生人问我的p(末日)是多少，就像在问洗手间怎么走一样随意。“几乎每一场晚餐谈话都会提起，”云数据平台Box首席执行官艾伦·勒维对我说。
P(末日)甚至在上月OpenAI事变中对扮演了一定的角色。席尔被任命为OpenAI临时负责人后，公司雇员之间开始转发他在近日一期博客上的言论，称他的p(末日)可能高达50%。一位讨论时在场的人士说，有员工担心他是个“末日论者”，由于认为这太过冒险，他可能会寻求延缓或限制他们的工作。（被罢免的OpenAI首席执行官萨姆·奥尔特曼最终恢复原职，因此这件事也就无关紧要了。）
当然，科幻迷很久以前就已经开始推想机器人篡夺世界的景象。但在去年ChatGPT推出后，这种威胁似乎显得更真切了。毕竟如果AI模型可以赢得艺术奖项，通过律师资格考试，那么距离劫难还能有多远？
AI行内人也在发出警告。去年从谷歌辞职的著名AI研究者杰弗里·辛顿开始警告AI的风险，他近日估计如果不施加有力的监管，AI在未来30年导致人类灭绝的可能性为10%。和辛顿一同被誉为“深度学习教父”的约书亚·本吉奥在接受采访时说，他认为发生AI大劫难的可能性大约在20%。
没人知道我们被AI杀死的概率是10%、20%还是85.2%。显然这个问题会引出更多的问题，比如：如果AI导致50%的人类死亡，还算“末日”吗？如果没有人死，但我们全都丢了工作，只能喝西北风呢？到底AI会如何接管世界呢？
但是p(末日)的重点不在于精确。它的目的是表明，在是乌托邦还是反乌托邦的问题上，一个人大致的立场如何，此外也是用模糊的经验论术语传达你在AI问题及其潜在影响上的关切程度。
这个术语似乎是十多年前在网络论坛LessWrong上出现的，那是一个理性主义哲学运动主题论坛。
LessWrong创始人是一位自学成才的AI研究者，名叫埃利泽·尤科夫斯基，他很早就产生了失控AI可能接管一切的想法，并就他设想的多种AI灾难场景撰文。（当时的AI连设置个厨房计时器都很勉强，因此风险显得十分遥远。）
后来成了AI世界最著名末日论者的尤科夫斯基告诉我，p(末日)这个词不是他提出的，不过他做了推广普及。（他还说，如果继续以现在的趋势发展，他的p(末日)是“有多高就多高”。）这个词后来被有效利他主义者们拿去用了，这个群体旨在通过逻辑推论得出有关公序良俗的理念。
我的猜测是，这个词最早是由身在波士顿的蒂姆·泰勒于2009年开始在LessWrong上使用的。泰勒在邮件往来中说到，他用这个词“指代末日出现的概率，同时又不需要详细阐明时间尺度或末日的定义。”
对一些人来说，谈论你的p(末日)无非就是在闲扯。然而在硅谷的一场激烈辩论中，它又成了一个重要的社交信号，辩论的一方认为AI发展过快，另一方认为应该更快。
Box首席执行官勒维属于较乐观的一方。他说他的p(末日)值很低——不是零，但“能多低就多低”——他认为我们能化解AI的巨大风险，避免最糟糕的结果。他担心的不是AI会杀死我们，而是监管者和立法者会利用这些可怕的末日预言，用来理直气壮地打压一个前景远大的年轻行业。
“如果在AI发展中过早开始关键的政策决断，是有可能出现过度干预的，”他说。
P(末日)的另一个问题是，在关乎存亡的问题上，乐观与悲观的界线是不明确的。比如，如果你预言AI有15%的可能杀死所有人类，你真的算AI乐观主义者？（换个说法：如果你认为你下一次乘坐飞机“只有”15%的几率机毁人亡，你会上飞机吗？）
研究AI风险的Open Philanthropy高级研究员阿杰亚·科特拉在p(末日)的问题上花了不少时间。她认为它作为一个简称可能是有用的——顺便一提，她的p(末日)是20%到30%之间——但同时也存在局限。首先p(末日)没有考虑到，AI相关破坏的可能性在很大程度上取决于我们打算如何治理它。
“我知道有些人的p(末日)超过90%了，这在一定程度上是因为他们认为企业和政府不会操心什么良好的安全实践和政策措施，”她对我说。“我也知道有些人的p(末日)不到5%，这部分是因为他们预计科学家和政策制定者会努力预防灾难的发生。”
换句话说，你可以把p(末日)当做某种墨迹测验——这个数据说的是AI，但说到底更多是在表明我们是怎么看待人类的，我们能不能在控制住风险的同时让强大的新技术为我们所用。
那么，你的p(末日)是多少？
Kevin Roose是《纽约时报》科技专栏作家和播客“Hard Fork”的主持人。点击查看更多关于他的信息。
翻译：杜然
(XYS20231210) "><meta name=og:image content="https://project-gutenberg.github.io/Pincong//images/card/177.jpg"><script data-ad-client=ca-pub-6074407261372769 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-06HJ1E5XNH"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-06HJ1E5XNH')</script></head><body><header class="fixed-top navigation"><div class=container><nav class="navbar navbar-expand-lg navbar-light bg-transparent"><a class=navbar-brand href=https://project-gutenberg.github.io/Pincong/><img class=img-fluid src=https://project-gutenberg.github.io/Pincong//images/logo.png alt=品葱*精选></a>
<button class="navbar-toggler border-0" type=button data-toggle=collapse data-target=#navigation>
<i class="ti-menu h3"></i></button><div class="collapse navbar-collapse text-center" id=navigation><ul class="navbar-nav ml-auto"><li class=nav-item><a class=nav-link href=https://project-gutenberg.github.io/Pincong/>Home</a></li><li class=nav-item><a class=nav-link href=https://project-gutenberg.github.io/Pincong/post/index.xml>RSS</a></li><li class=nav-item><a class=nav-link href=https://bit.ly/2HrxEi0>Telegram</a></li><li class=nav-item><a class=nav-link href=https://twitter.com/speechfree3>Twitter</a></li></ul></div></nav></div></header><div class="py-5 d-none d-lg-block"></div><section class=main-content><div class=container><div class=row><div class="col-lg-8 mx-auto block shadow mb-5"><h2>AI毁灭人类的“末日概率”是多少</h2><div class=mb-3><span>by <a href=https://project-gutenberg.github.io/Pincong/author/kevin>Kevin</a></span>,
<span>at 17 December 2023</span>, tags :
<a href=https://project-gutenberg.github.io/Pincong/tags/%e6%9c%ab%e6%97%a5>末日</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/openai>Open ai</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e8%ae%a4%e4%b8%ba>认为</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e6%89%a7%e8%a1%8c%e5%ae%98>执行官</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e6%96%b0%e8%af%ad%e4%b8%9d>新语丝</a>
<a href=https://github.com/Project-Gutenberg/Pincong-data/edit/master/site/content/post/c788821be104ba29ba84e999cc4ab8b5.md style=color:gray><strong><i>点击纠错</i></strong></a>
<i></i><a href=https://github.com/Project-Gutenberg/Pincong-data/delete/master/site/content/post/c788821be104ba29ba84e999cc4ab8b5.md style=color:gray><strong><i>点击删除</i></strong></a></div><h5><a href=https://bit.ly/justmysock>使用CN2/CN2GIA顶级线路，支持Shadowsocks/V2ray科学上网，支持支付宝付款，每月仅需 5 美元</a></h5><h5><a href=https://bit.ly/2HrxEi0>## 加入品葱精选 Telegram Channel ##</a></h5><p></p><p>AI毁灭人类的“末日概率”是多少</p><p>作者：KEVIN ROOSE　　2023年12月6日纽约时报</p><p>本文是“交易录峰会”(DealBook Summit)特别报道的一部分，该峰会得到了世界各地商业及政策领袖的参与。</p><p>AI公司Anthropic的首席执行官达里奥·阿莫代伊给出的数字是10%到25%之间。联邦贸易委员会主席丽娜·汗近日告诉我，她认为的数值是15%。上月担任了五分钟的OpenAI临时首席执行官的艾米特·席尔告诉我，他得出的数值游移在5%到50%之间。</p><p>我这里说的，当然就是p(末日)了，这是硅谷正在热议的一项令人毛骨悚然的新数据。</p><p>P(末日)——就是用数学的方式表达“末日的概率”——是一些人工智能研究者在表达他们认为AI有多大可能把我们杀光，或创造别的什么威胁人类生存的灾变。P(末日)高意味着你认为AI末日的可能性大，低意味着你认为我们有机会挺过去。</p><p>P(末日)曾经只是网络论坛上一帮AI技术宅之间心领神会的笑话，但随着去年ChatGPT点燃的AI热让人对AI的进步之快产生恐惧，近几个月这个词进入了主流。</p><p>它已经成了旧金山技术人士交谈时常用的开场白——也是AI文化里躲不开的一部分。今年我在两场业界活动上遇到陌生人问我的p(末日)是多少，就像在问洗手间怎么走一样随意。“几乎每一场晚餐谈话都会提起，”云数据平台Box首席执行官艾伦·勒维对我说。</p><p>P(末日)甚至在上月OpenAI事变中对扮演了一定的角色。席尔被任命为OpenAI临时负责人后，公司雇员之间开始转发他在近日一期博客上的言论，称他的p(末日)可能高达50%。一位讨论时在场的人士说，有员工担心他是个“末日论者”，由于认为这太过冒险，他可能会寻求延缓或限制他们的工作。（被罢免的OpenAI首席执行官萨姆·奥尔特曼最终恢复原职，因此这件事也就无关紧要了。）</p><p>当然，科幻迷很久以前就已经开始推想机器人篡夺世界的景象。但在去年ChatGPT推出后，这种威胁似乎显得更真切了。毕竟如果AI模型可以赢得艺术奖项，通过律师资格考试，那么距离劫难还能有多远？</p><p>AI行内人也在发出警告。去年从谷歌辞职的著名AI研究者杰弗里·辛顿开始警告AI的风险，他近日估计如果不施加有力的监管，AI在未来30年导致人类灭绝的可能性为10%。和辛顿一同被誉为“深度学习教父”的约书亚·本吉奥在接受采访时说，他认为发生AI大劫难的可能性大约在20%。</p><p>没人知道我们被AI杀死的概率是10%、20%还是85.2%。显然这个问题会引出更多的问题，比如：如果AI导致50%的人类死亡，还算“末日”吗？如果没有人死，但我们全都丢了工作，只能喝西北风呢？到底AI会如何接管世界呢？</p><p>但是p(末日)的重点不在于精确。它的目的是表明，在是乌托邦还是反乌托邦的问题上，一个人大致的立场如何，此外也是用模糊的经验论术语传达你在AI问题及其潜在影响上的关切程度。</p><p>这个术语似乎是十多年前在网络论坛LessWrong上出现的，那是一个理性主义哲学运动主题论坛。</p><p>LessWrong创始人是一位自学成才的AI研究者，名叫埃利泽·尤科夫斯基，他很早就产生了失控AI可能接管一切的想法，并就他设想的多种AI灾难场景撰文。（当时的AI连设置个厨房计时器都很勉强，因此风险显得十分遥远。）</p><p>后来成了AI世界最著名末日论者的尤科夫斯基告诉我，p(末日)这个词不是他提出的，不过他做了推广普及。（他还说，如果继续以现在的趋势发展，他的p(末日)是“有多高就多高”。）这个词后来被有效利他主义者们拿去用了，这个群体旨在通过逻辑推论得出有关公序良俗的理念。</p><p>我的猜测是，这个词最早是由身在波士顿的蒂姆·泰勒于2009年开始在LessWrong上使用的。泰勒在邮件往来中说到，他用这个词“指代末日出现的概率，同时又不需要详细阐明时间尺度或末日的定义。”</p><p>对一些人来说，谈论你的p(末日)无非就是在闲扯。然而在硅谷的一场激烈辩论中，它又成了一个重要的社交信号，辩论的一方认为AI发展过快，另一方认为应该更快。</p><p>Box首席执行官勒维属于较乐观的一方。他说他的p(末日)值很低——不是零，但“能多低就多低”——他认为我们能化解AI的巨大风险，避免最糟糕的结果。他担心的不是AI会杀死我们，而是监管者和立法者会利用这些可怕的末日预言，用来理直气壮地打压一个前景远大的年轻行业。</p><p>“如果在AI发展中过早开始关键的政策决断，是有可能出现过度干预的，”他说。</p><p>P(末日)的另一个问题是，在关乎存亡的问题上，乐观与悲观的界线是不明确的。比如，如果你预言AI有15%的可能杀死所有人类，你真的算AI乐观主义者？（换个说法：如果你认为你下一次乘坐飞机“只有”15%的几率机毁人亡，你会上飞机吗？）</p><p>研究AI风险的Open Philanthropy高级研究员阿杰亚·科特拉在p(末日)的问题上花了不少时间。她认为它作为一个简称可能是有用的——顺便一提，她的p(末日)是20%到30%之间——但同时也存在局限。首先p(末日)没有考虑到，AI相关破坏的可能性在很大程度上取决于我们打算如何治理它。</p><p>“我知道有些人的p(末日)超过90%了，这在一定程度上是因为他们认为企业和政府不会操心什么良好的安全实践和政策措施，”她对我说。“我也知道有些人的p(末日)不到5%，这部分是因为他们预计科学家和政策制定者会努力预防灾难的发生。”</p><p>换句话说，你可以把p(末日)当做某种墨迹测验——这个数据说的是AI，但说到底更多是在表明我们是怎么看待人类的，我们能不能在控制住风险的同时让强大的新技术为我们所用。</p><p>那么，你的p(末日)是多少？</p><p>Kevin Roose是《纽约时报》科技专栏作家和播客“Hard Fork”的主持人。点击查看更多关于他的信息。</p><p>翻译：杜然</p><p>(XYS20231210)</p><h5><a href="https://www.digitalocean.com/?refcode=4351d40e44b2&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=CopyPaste">最简单好用的 VPS,没有之一，注册立得 100 美金</a></h5></div><div class="col-lg-8 mx-auto block shadow"><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var t=document,e=t.createElement('script');e.async=!0,e.src='//pin-cong-jing-xuan.disqus.com/embed.js',e.setAttribute('data-timestamp',+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><div class="col-lg-8 mx-auto block shadow"><h3>See Also</h3><div class=container><div class=row><div class="mx-auto px-0"><div class="bg-white shadow block"><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/3007bc105fc9b12010126ed704315899/?utm_source=see_also&utm_medium=ai%25E6%25AF%2581%25E7%2581%25AD%25E4%25BA%25BA%25E7%25B1%25BB%25E7%259A%2584%25E6%259C%25AB%25E6%2597%25A5%25E6%25A6%2582%25E7%258E%2587%25E6%2598%25AF%25E5%25A4%259A%25E5%25B0%2591">人工智能将把我们带往天堂还是地狱</a></h2><p class=text-dark>人工智能将把我们带往天堂还是地狱
作者：DAVID BROOKS　2023年11月23日纽约时报
OpenAI的优点之一是，它建立在不信任的基础上。它最初是一个非营利性的研究实验室，因为它的创始人认为，人工智能不应该由主要受利润驱动的商业公 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/375fd2cb9296da2fcd58966db04356d5/?utm_source=see_also&utm_medium=ai%25E6%25AF%2581%25E7%2581%25AD%25E4%25BA%25BA%25E7%25B1%25BB%25E7%259A%2584%25E6%259C%25AB%25E6%2597%25A5%25E6%25A6%2582%25E7%258E%2587%25E6%2598%25AF%25E5%25A4%259A%25E5%25B0%2591">“眯眯眼”怎么就“辱华”了？</a></h2><p class=text-dark>“眯眯眼”怎么就“辱华”了？
·方舟子·
国内一家卖零食的食品公司“三只松鼠”，被人翻出来在两年前拍过一组广告，上面的模特眼睛比较小，也就是所谓的“眯眯眼”，而不是那种大眼的美女。小粉红、五毛、战狼指责这家公司故意找一个眯眯眼当模特拍广告， …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/f65e62eeffbecfaf383e1b3dbe9cff0c/?utm_source=see_also&utm_medium=ai%25E6%25AF%2581%25E7%2581%25AD%25E4%25BA%25BA%25E7%25B1%25BB%25E7%259A%2584%25E6%259C%25AB%25E6%2597%25A5%25E6%25A6%2582%25E7%258E%2587%25E6%2598%25AF%25E5%25A4%259A%25E5%25B0%2591">新译 王吉民 伍连德 《中国医史》上篇 第十四章 宋代名医</a></h2><p class=text-dark>新译 王吉民 伍连德 《中国医史》上篇 第十四章 宋代名医
第十四章
宋代名医
大海就是一切 译 梦妈 审校
钱乙，字仲阳，原籍浙江钱塘。他的祖上北移迁居郓州。慈母早逝，他的父亲是一位善于针灸的医师，但好喝酒喜欢游荡，在钱乙三岁的时候就抛家 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/e29b1f5388f511ae615d0af788c1558c/?utm_source=see_also&utm_medium=ai%25E6%25AF%2581%25E7%2581%25AD%25E4%25BA%25BA%25E7%25B1%25BB%25E7%259A%2584%25E6%259C%25AB%25E6%2597%25A5%25E6%25A6%2582%25E7%258E%2587%25E6%2598%25AF%25E5%25A4%259A%25E5%25B0%2591">流氓教授傅谨，你还要作恶到何时</a></h2><p class=text-dark>流氓教授傅谨，你还要作恶到何时
作者：徐晨
本人徐晨，女，1989年生，2019年中国传媒大学博士毕业，随后到浙江传媒学院任职。现实名举报山东师范大学新闻与传媒学院院长、中国文艺评论家协会副主席、第七届国务院学位委员会学科评议组（戏剧与影视 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/b00ce739ab98295d704ead0e42956e38/?utm_source=see_also&utm_medium=ai%25E6%25AF%2581%25E7%2581%25AD%25E4%25BA%25BA%25E7%25B1%25BB%25E7%259A%2584%25E6%259C%25AB%25E6%2597%25A5%25E6%25A6%2582%25E7%258E%2587%25E6%2598%25AF%25E5%25A4%259A%25E5%25B0%2591">确实有癌症能传染，但不是你想的那样</a></h2><p class=text-dark>确实有癌症能传染，但不是你想的那样
作者：王晨光
中山二院“集体患癌”事件早期，有一位以业余科普作家身份出现的“呼吸科邹医生”，在自己的微信公众号中发表《中山大学孙逸仙纪念医院苏士成教授团队学生集体患癌，可怕的背后真相》一文，给出了除致癌试 …</p></article></div></div></div></div></div></div></div></div></section><script>var i,images=document.getElementsByTagName("img");for(i=0;i<images.length;i++)images[i].className+="img-fluid w-100 mb-4"</script><footer class="py-4 bg-light border-top"><div class=container><div class="row justify-content-between align-items-center"><div class="col-lg-4 text-center text-lg-left mb-4 mb-lg-0"><a href=https://project-gutenberg.github.io/Pincong/><img src=https://project-gutenberg.github.io/Pincong//images/logo.png class=img-fluid alt=品葱*精选></a></div><div class="col-lg-4 text-center mb-4 mb-lg-0"><ul class="list-inline mb-0"></ul></div><div class="col-lg-4 text-lg-right text-center mb-4 mb-lg-0"><ul class="list-inline social-icon mb-0"><li class=list-inline-item><a href=https://pincong.rocks/><i class=ti-home></i></a></li><li class=list-inline-item><a href=https://github.com/Project-Gutenberg/Pincong><i class=ti-github></i></a></li></ul></div><div class="col-12 text-center mt-4"><span></span></div></div></div></footer><script src=../../plugins/jQuery/jquery.min.js></script>
<script src=../../plugins/bootstrap/bootstrap.min.js></script>
<script src=../../plugins/search/fuse.min.js></script>
<script src=../../plugins/search/mark.js></script>
<script src=../../plugins/search/search.js></script>
<script src=https://project-gutenberg.github.io/Pincong/js/script.min.js></script>
<script>(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)})(window,document,'script','//www.google-analytics.com/analytics.js','ga'),ga('create','UA-151212685-6','auto'),ga('send','pageview')</script></body></html>