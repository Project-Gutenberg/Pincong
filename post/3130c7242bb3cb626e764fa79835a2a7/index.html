<!doctype html><html lang=zh-cn><head><meta charset=utf-8><title>华人制霸CVPR：斩获全部奖项，四成作者来自中国，清华排名第一​</title><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content=" 在今年的计算机视觉顶级学术会议 CVPR 上，华人再次成为最大赢家。
包括经典论文、最佳论文、最佳学生论文和年轻学者奖等几大奖项，全部由华人包揽，并且论文类奖项还都是华人第一作者！
不仅如此，根据主席团的介绍，来自中国的作者在本次 CVPR 投稿论文中占了足足四成，并且投稿最多的前五家机构当中，就有四家国内顶尖大学！
CVPR 一直是华人研究员施展拳脚的舞台，不过这次已经不能用收获颇丰来形容了——他们和各自的作品，在本次 CVPR 2020 上大放异彩，堪比夜空中最亮的星。
01
最佳论文奖
CVPR 每年都会颁发多个奖项，其中最佳论文奖 (Best Paper Award) 是压轴奖项，颁发给评委会认为今年所有接收论文当中质量最高的王者级论文。
今年 CVPR 2020 的最佳论文奖，颁发给了 _Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild. _
第一作者为牛津大学视觉几何组博士生吴尚哲，本科毕业于香港科技大学，曾在商汤、腾讯优图、Google AI 实习。
简单来说，这篇论文提出了一种新的方法 Photo-Geometric Autoencoding: 只用一张人脸图像，可靠地“还原”（实际上是生成）高质量的三维人脸模型。
稍微具体来说，这种方法在无监督的前提下，对一张照片采用多个 encoder-decoder 网络进行拆解，生成深度图、光照图、视角等多个维度的图片，组合渲染，重构出三维人脸模型。
除了真人头像之外，写实绘画，甚至抽象作品里的人脸也可以重建，看起来有点惊悚，不过对于这个模型来说还是足以证明其实力的：
也可以对视频进行实时重建： "><meta name=generator content="Hugo 0.100.2"><link rel=stylesheet href=../../plugins/bootstrap/bootstrap.min.css><link rel=stylesheet href=../../plugins/themify-icons/themify-icons.css><link rel=stylesheet href=https://project-gutenberg.github.io/Pincong/scss/style.min.css media=screen><link rel="shortcut icon" href=https://project-gutenberg.github.io/Pincong/images/favicon.png type=image/x-icon><link rel=icon href=https://project-gutenberg.github.io/Pincong/images/favicon.png type=image/x-icon><meta name=twitter:card content="summary_large_image"><meta name=og:title content=" 华人制霸CVPR：斩获全部奖项，四成作者来自中国，清华排名第一​ "><meta name=og:description content=" 在今年的计算机视觉顶级学术会议 CVPR 上，华人再次成为最大赢家。
包括经典论文、最佳论文、最佳学生论文和年轻学者奖等几大奖项，全部由华人包揽，并且论文类奖项还都是华人第一作者！
不仅如此，根据主席团的介绍，来自中国的作者在本次 CVPR 投稿论文中占了足足四成，并且投稿最多的前五家机构当中，就有四家国内顶尖大学！
CVPR 一直是华人研究员施展拳脚的舞台，不过这次已经不能用收获颇丰来形容了——他们和各自的作品，在本次 CVPR 2020 上大放异彩，堪比夜空中最亮的星。
01
最佳论文奖
CVPR 每年都会颁发多个奖项，其中最佳论文奖 (Best Paper Award) 是压轴奖项，颁发给评委会认为今年所有接收论文当中质量最高的王者级论文。
今年 CVPR 2020 的最佳论文奖，颁发给了 _Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild. _
第一作者为牛津大学视觉几何组博士生吴尚哲，本科毕业于香港科技大学，曾在商汤、腾讯优图、Google AI 实习。
简单来说，这篇论文提出了一种新的方法 Photo-Geometric Autoencoding: 只用一张人脸图像，可靠地“还原”（实际上是生成）高质量的三维人脸模型。
稍微具体来说，这种方法在无监督的前提下，对一张照片采用多个 encoder-decoder 网络进行拆解，生成深度图、光照图、视角等多个维度的图片，组合渲染，重构出三维人脸模型。
除了真人头像之外，写实绘画，甚至抽象作品里的人脸也可以重建，看起来有点惊悚，不过对于这个模型来说还是足以证明其实力的：
也可以对视频进行实时重建： "><meta name=og:image content="https://project-gutenberg.github.io/Pincong//images/card/48.jpg"><script data-ad-client=ca-pub-6074407261372769 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-06HJ1E5XNH"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-06HJ1E5XNH')</script></head><body><header class="fixed-top navigation"><div class=container><nav class="navbar navbar-expand-lg navbar-light bg-transparent"><a class=navbar-brand href=https://project-gutenberg.github.io/Pincong/><img class=img-fluid src=https://project-gutenberg.github.io/Pincong//images/logo.png alt=品葱*精选></a>
<button class="navbar-toggler border-0" type=button data-toggle=collapse data-target=#navigation>
<i class="ti-menu h3"></i></button><div class="collapse navbar-collapse text-center" id=navigation><ul class="navbar-nav ml-auto"><li class=nav-item><a class=nav-link href=https://project-gutenberg.github.io/Pincong/>Home</a></li><li class=nav-item><a class=nav-link href=https://project-gutenberg.github.io/Pincong/post/index.xml>RSS</a></li><li class=nav-item><a class=nav-link href=https://bit.ly/2HrxEi0>Telegram</a></li><li class=nav-item><a class=nav-link href=https://twitter.com/speechfree3>Twitter</a></li></ul></div></nav></div></header><div class="py-5 d-none d-lg-block"></div><section class=main-content><div class=container><div class=row><div class="col-lg-8 mx-auto block shadow mb-5"><h2>华人制霸CVPR：斩获全部奖项，四成作者来自中国，清华排名第一​</h2><div class=mb-3><span>by <a href=https://project-gutenberg.github.io/Pincong/author/%e5%85%89%e8%b0%b1nbsp%e6%9d%9c%e6%99%a8>光谱&amp;Nbsp;杜晨</a></span>,
<span>at 17 June 2020</span>, tags :
<a href=https://project-gutenberg.github.io/Pincong/tags/%e8%ae%ba%e6%96%87>论文</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e6%9c%80%e4%bd%b3>最佳</a>
<a href=https://project-gutenberg.github.io/Pincong/tags/%e6%8a%95%e7%a8%bf>投稿</a>
<a href=https://github.com/Project-Gutenberg/Pincong-data/edit/master/site/content/post/3130c7242bb3cb626e764fa79835a2a7.md style=color:gray><strong><i>点击纠错</i></strong></a>
<i></i><a href=https://github.com/Project-Gutenberg/Pincong-data/delete/master/site/content/post/3130c7242bb3cb626e764fa79835a2a7.md style=color:gray><strong><i>点击删除</i></strong></a></div><h5><a href=https://bit.ly/justmysock>使用CN2/CN2GIA顶级线路，支持Shadowsocks/V2ray科学上网，支持支付宝付款，每月仅需 5 美元</a></h5><h5><a href=https://bit.ly/2HrxEi0>## 加入品葱精选 Telegram Channel ##</a></h5><p></p><p>在今年的计算机视觉顶级学术会议 CVPR 上，华人再次成为最大赢家。</p><p><strong>包括经典论文、最佳论文、最佳学生论文和年轻学者奖等几大奖项，全部由华人包揽，并且论文类奖项还都是华人第一作者！</strong></p><p><strong>不仅如此，根据主席团的介绍，来自中国的作者在本次 CVPR 投稿论文中占了足足四成，并且投稿最多的前五家机构当中，就有四家国内顶尖大学！</strong></p><p>CVPR 一直是华人研究员施展拳脚的舞台，不过这次已经不能用收获颇丰来形容了——他们和各自的作品，在本次 CVPR 2020 上大放异彩，堪比夜空中最亮的星。</p><p>01</p><p><strong>最佳论文奖</strong></p><p>CVPR 每年都会颁发多个奖项，其中最佳论文奖 (Best Paper Award) 是压轴奖项，颁发给评委会认为今年所有接收论文当中质量最高的王者级论文。</p><p><strong>今年 CVPR 2020 的最佳论文奖，颁发给了 _Unsupervised Learning of Probably Symmetric Deformable 3D Objects from Images in the Wild. _</strong></p><p><strong>第一作者为牛津大学视觉几何组博士生吴尚哲，本科毕业于香港科技大学，曾在商汤、腾讯优图、Google AI 实习。</strong></p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSMhrevD68o0jjpw3QicfKbibnbxSQBG0dB510tsXjBHibNDhFHL1mKlDd7w/640%3Fwx_fmt%3Djpeg" alt></p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSMOkecH6lTeCdrbCMevUDcYLEfPVcELyBiaK0TZVPOia9px3s55g6Rib6Cw/640%3Fwx_fmt%3Djpeg" alt></p><p>简单来说，这篇论文提出了一种新的方法 Photo-Geometric Autoencoding: <strong>只用一张人脸图像，可靠地“还原”（实际上是生成）高质量的三维人脸模型。</strong></p><p><strong><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSMq6umFwzHgIeG7jSB9MIJXBSgnWx6EaKpIzrHWVCq88K9TAQGE8sufQ/640%3Fwx_fmt%3Djpeg" alt></strong></p><p>稍微具体来说，这种方法在无监督的前提下，对一张照片采用多个 encoder-decoder 网络进行拆解，生成深度图、光照图、视角等多个维度的图片，组合渲染，重构出三维人脸模型。</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_gif/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSMh137WccIgBiawb1iaWia9dRQm3BBT6FYh6N1MoIar04FYicryAYmAAibRbw/640%3Fwx_fmt%3Dgif" alt></p><p>除了真人头像之外，写实绘画，甚至抽象作品里的人脸也可以重建，看起来有点惊悚，不过对于这个模型来说还是足以证明其实力的：</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSM1F2MvjIWs6icicYdpvpVSDZnByvEorkw9vkmyw5JPxicL0LibCCOLiaIt2g/640%3Fwx_fmt%3Djpeg" alt></p><p>也可以对视频进行实时重建：</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_gif/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSM9Bw1D5UC8d40y3VKfsicLdMOPEJR8VnlEtI1JqjAvibdIZJHbnUlSOUQ/640%3Fwx_fmt%3Dgif" alt></p><p>当然，掺点猫进来才会火：</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_gif/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSMg4MCicwMaic6rL6mlIR0OewuceaX1NIBCfB0WOdHVqUy0fen0cTTRpGA/640%3Fwx_fmt%3Dgif" alt></p><p>作者也提供了一个 demo 的在线网站 <a href=https://bit.ly/30KfQWB>https://bit.ly/30KfQWB</a>，你可以自己上传一张照片试试效果。不过不知道是不是这个模型对亚洲脸型的识别能力差点意思，把我的人脸重建的不是很像……</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSMibGLYz7Kq9OMIrMLrnjJvPhSKnDPvCLdR4ANaZtzz9Z3ECJSP5iaMSEw/640%3Fwx_fmt%3Djpeg" alt></p><p>02</p><p><strong>最佳学生论文奖</strong></p><p>最佳学生论文奖颁发给那些第一作者是学生身份的优秀论文。</p><p><strong>CVPR 2020 的最佳学生论文奖，颁发给了加拿大 Simon Fraser University 团队的 <em>BSP-Net: Generating Compact Meshes via Binary Space Partitioning</em> 一文。</strong></p><p><strong>第一作者该校图形和视觉实验室的博士生 Zhiqin Chen，本科毕业于上海交通大学计算机系。</strong></p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSMp7E7gjf7J5sIPLx2N5icOFFdsJv6B4xq4kib5oH3OlO9CkaB0z5vobhA/640%3Fwx_fmt%3Djpeg" alt></p><p>作者 Chen 同学的 Twitter 简介自己是一名重度游戏上瘾者。他的这篇论文 BSP-Net 正是如此，利用了游戏开发中经常用到的一个3D计算机图形概念，叫做二叉空间分割 (Binary Space Partitioning, BSP)。</p><p>简单来说，BSP 就是把一个复杂形状（二维或三维）的物体，在形状和对应的数据上分割细化成树状结构。这样，游戏能够快速生成和渲染由大量多边形组合成的物体和场景——这项技术最早被《雷神之锤》、《德军总部3D》和《毁灭战士》都采用过，在碰撞侦测、光线追踪等众多游戏技术当中有着大量运用。</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSMlqgq13X6wQA4mhKUx9muhlrVyKvDV6ibPaicLibunDHX2sowALfBzPa9A/640%3Fwx_fmt%3Dpng" alt></p><p>作者基于 BSP 开发的这个神经网络 BSP-Net，主要功能和设计方向是自动生成最少的多边形，合成外形尽量完美、真实的三维物体。</p><p>对同一个二维或者三维图形物体进行重建，和此领域其它神经网络模型相比，BSP-Net 所用的多边形数量显著更少，镶嵌效果更好。</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSMUbpC0tic3KhK0ic7nsBwCftUp3R5fszSK8AxYy7Lae0IJY8fqsg3iaXxg/640%3Fwx_fmt%3Djpeg" alt></p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSM1QxnzheWK2kfe44W5EK3QFHic1uEfj5qgRic7xNMSj7gniaQjkeIoLiaHw/640%3Fwx_fmt%3Dpng" alt></p><p>而这在某些专门的应用领域或许能派上大用场，比如游戏——可以减少占用计算资源耗用，还能渲染更多的物体。这并不是说 BSP-Net 的重建效果是最完美的，正如前面提到，它的主要方向是降低多边形数量，同时达到预期的效果。</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSMLlEZm28H4icXV54cVDiceGq1gFsf1BumaaWq4ia3ITKWRtfnLpPlVmwoQ/640%3Fwx_fmt%3Djpeg" alt></p><p>你可以到项目网页 <a href=https://bsp-net.github.io/>https://bsp-net.github.io/</a> 上查看关于这篇论文的概括介绍、口述演讲和更多细节。</p><p>03</p><p><strong>经典论文奖</strong></p><p>这个奖项全名 PAMI Longuet-Higgins Prize，旨在奖励那些发布时间已经超过十年，但对后世研究者的工作仍然具有突出的指导和启发意义的经典论文。</p><p><strong>这一奖项（两个名额的其中之一）同样被华人第一作者的论文拿下：来自当时在布朗大学读 PhD，后来辗转哈佛大学、英伟达，现在在谷歌工作的高级研究员 Deqing Sun. 论文：<em>Secrets of Optical Flow Estimation and Their Principles.</em></strong></p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSMykd5pJeHiaic26KaNRRUwZMnowHTM5fhmF8PzfDD0bHRPPn0QwrgA9sg/640%3Fwx_fmt%3Djpeg" alt></p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSMBWMz2ISZsPcqP9THS0E3YFoMwcD0ibh0mV7DVg45ib6OKOhCMAphiauWg/640%3Fwx_fmt%3Djpeg" alt></p><p>这篇论文在 CVPR 2010 上首次发布，当时只是一篇 poster 论文。它讲的是光流法测算，也就是和观察者的运动所造成的观测目标、表面或边缘运动有关的一个概念。比如某人观测到某物体向右上方移动，如何判定这种相对位移是观测对象还是观测者在动，便是光流法测算需要解决的问题。</p><p>这个概念在模式识别、计算机视觉和其它图像处理领域都非常重要，是视频压缩、物体识别和追踪、机器人导航等领域的关键底层技术。</p><p>而这篇十年前的论文，通过大量建模、测试等工作，解答了许多光流法测算相关的问题，从数学/机器学习的角度分析了当代光流法测算能够取得准确结果的理由，哪些技巧好用，哪些没用，并且延展到如何利用这些新增的知识继续改进测算技巧，开发出新的模型。</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSM6TRJeuhWgk7Cgqr3EDvSgolibspp5pGr4ic2r2PPjEus28S8G8WDSvUw/640%3Fwx_fmt%3Dpng" alt></p><p>CVPR 2020 评审团认为，回顾十年前来看，这篇论文对后世研究的积极影响最为重大，所以颁发了经典论文奖给它。</p><p>同时，Deqing Sun 也和 Google Research 的 Jon Barron（Pixel 手机的背景虚化、HDR+、人像模式以及 Google Glass 重要开发者）共同荣获本届 CVPR 的年轻学者奖 (PAMI Young Researcher Award)</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSMDWaTAmzDTsJbFreichx5zpBePRDtMSO4asiaQw4jxTSGTtX4aR4QfZnQ/640%3Fwx_fmt%3Djpeg" alt></p><p>04</p><p><strong>中国研究员继续大放异彩</strong></p><p>照例，主席团成员在这次线上大会开场阶段介绍了本届 CVPR 的投稿论文作者和机构情况。</p><p>由于新冠疫情影响，CVPR 2020 从原本的线下会议，一度想要变成线上线下混合，最后失败，只能完全转为线上，注册参会者只有7,000人左右，比去年有所降低。</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSMhegcCvzh7MtTWeux9HnVoibuicyicWD0Z4YcHCW4DvBZiaxCyiaszBIJCCw/640%3Fwx_fmt%3Djpeg" alt></p><p>不过在论文投稿方面，大会还是继承了越办越好的传统，投稿论文数量增加了29%，作者数量增加了20%。最终接收论文也有1,467篇，较去年有所提升，占总投稿数量的四分之一；Oral 论文比例5.7%。</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSM0xTImyMe3qgib4hFJ0O4LfzQs3Lj6HegsicuOeLDnaKqfXicqwJLwsMsA/640%3Fwx_fmt%3Djpeg" alt></p><p>**来自中国作者和/或中国机构的论文占了最大的比例。大会数据统计，**来自中国的作者占到了四成，远超美国22.7%。</p><p>**更重要的是，中国作者/机构的论文不仅数量多，质量也很高，**不仅如前面提到的，斩获最佳论文、最佳学生论文和经典论文三大奖，在各奖项提名名单里也占了绝大多数。</p><p><strong>按照归属机构统计作者发现，中国大学在前十当中占了七名，前五当中占了四名！</strong></p><p>它们分别是：<strong>清华大学（第一，340人）</strong>、上海交大（第三，287人）、北大（第四，232人）、浙大（第五，216人）、中科大（第七、180人）、北航和西电（并列九、十名、各138人）。</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KQHbxibTNbDoKPiaQ2okgJtSMjNxFckQiaJcbVzf2jlw5VUPELtRVNz38p2Jk56J0QeWiaoiafJWSWMsFQ/640%3Fwx_fmt%3Djpeg" alt></p><p><strong>去年 CVPR 的大奖同样属于华人团队。</strong></p><p>CVPR 2019 最佳论文得主 CMU 辛书冕和团队通过提取优先、零碎和非直接的光学信息，能够隔着障碍物还原出另外一边非视距内物体的样貌。大会评价称：“该论文在非视距重建（也即看到拐角背后）上作出了杰出的贡献。这是一篇理论优美且具有启发价值的论文，扩展了计算机视觉可能性的边界。”</p><p>最佳学生论文奖颁发给了 UCSB 王鑫和团队，他们开发的自我监督学习模型可以让机器人遵守自然语言指令序列进行视觉导航，对应论文在去年所有投稿文章中得分排名第一。</p><p>经典论文奖则毫无悬念地颁给了斯坦福邓嘉和李飞飞团队的 ImageNet 论文。ImageNet 作为一个大规模的标注图像数据库，为后世研究者提供了极大的便利，促进了计算机视觉技术的进步。</p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/cn2WtQ1Q5KSaAibwHE1Y48uXsicqOmbWWEKEZknqxMIqEGuOAKqiaQ0GAicbKfcxUCJibicvcBzRoH0CP29EHADIjLUA/640%3Fwx_fmt%3Dpng" alt></p><p><strong>喜欢这篇文章？</strong></p><p><strong>1）点击右下角的“在看”</strong></p><p><strong>2）分享到你的朋友圈和群里</strong></p><p><strong>3）赶快关注硅星人吧！</strong></p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/cn2WtQ1Q5KTjx9juhZk9WPSllLiaC5vBicRtmaOrnCotPWjGJc6oGNkX0dxbZDmWegHfD1icESicIK4UeDD0w31XDA/640%3Fwx_fmt%3Dpng" alt></p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_jpg/cn2WtQ1Q5KTjx9juhZk9WPSllLiaC5vBicwzhpDG8f4ZZ4nPGRODGVKgnj2Sy3MasUjFQtyJ89CrYmApfnHO4mZw/640%3Fwx_fmt%3Djpeg" alt></p><p><img src="https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/cn2WtQ1Q5KTjx9juhZk9WPSllLiaC5vBicfUJSQmXfkDib2Wv0QcMjQLMnppOd0ppWwZlFwLQ1Tqr4ToPXTImNTrQ/640%3Fwx_fmt%3Dpng" alt></p><p>关注硅星人，你就能了解硅谷最新的科技进展和湾区的大事小情，变身最in技术潮人</p><h5><a href="https://www.digitalocean.com/?refcode=4351d40e44b2&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=CopyPaste">最简单好用的 VPS,没有之一，注册立得 100 美金</a></h5></div><div class="col-lg-8 mx-auto block shadow"><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return}var t=document,e=t.createElement('script');e.async=!0,e.src='//pin-cong-jing-xuan.disqus.com/embed.js',e.setAttribute('data-timestamp',+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><div class="col-lg-8 mx-auto block shadow"><h3>See Also</h3><div class=container><div class=row><div class="mx-auto px-0"><div class="bg-white shadow block"><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/4e4a28b2c61cd2827ebafee1ad701fc4/?utm_source=see_also&utm_medium=%25E5%258D%258E%25E4%25BA%25BA%25E5%2588%25B6%25E9%259C%25B8cvpr%25E6%2596%25A9%25E8%258E%25B7%25E5%2585%25A8%25E9%2583%25A8%25E5%25A5%2596%25E9%25A1%25B9%25E5%259B%259B%25E6%2588%2590%25E4%25BD%259C%25E8%2580%2585%25E6%259D%25A5%25E8%2587%25AA%25E4%25B8%25AD%25E5%259B%25BD%25E6%25B8%2585%25E5%258D%258E%25E6%258E%2592%25E5%2590%258D%25E7%25AC%25AC%25E4%25B8%2580">预印本是与非 – Nei.st</a></h2><p class=text-dark>新冠疫情期间迅速崛起的预印本平台利弊皆显。在「及时分享」与「质量把关」之间，它和传统学术出版行业都在寻找着平衡点
一场史无前例的新冠疫情，让一种后起的科研论文发表平台——预印本网站的影响力大增，争议也随之而来。
2020 年 1 月的最后一 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/2bc8810f164b6b35a7663ba17283e8a6/?utm_source=see_also&utm_medium=%25E5%258D%258E%25E4%25BA%25BA%25E5%2588%25B6%25E9%259C%25B8cvpr%25E6%2596%25A9%25E8%258E%25B7%25E5%2585%25A8%25E9%2583%25A8%25E5%25A5%2596%25E9%25A1%25B9%25E5%259B%259B%25E6%2588%2590%25E4%25BD%259C%25E8%2580%2585%25E6%259D%25A5%25E8%2587%25AA%25E4%25B8%25AD%25E5%259B%25BD%25E6%25B8%2585%25E5%258D%258E%25E6%258E%2592%25E5%2590%258D%25E7%25AC%25AC%25E4%25B8%2580">论文造假潮背后：SCI 与中国科研三十年｜大象公会</a></h2><p class=text-dark>三十年来与国际接轨的中国科研，又到了十字路口。
文｜朱不换
5 月 29 日，知名生物学界打假人士 Bik 爆料，江苏、河南、福建、辽宁、山东多家知名医院医生的科研论文涉嫌学术不端、数据雷同。中国 SCI 论文组团涉假的问题，又一次浮出水 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/1ee1c7bc92a198e81151a288a59d1655/?utm_source=see_also&utm_medium=%25E5%258D%258E%25E4%25BA%25BA%25E5%2588%25B6%25E9%259C%25B8cvpr%25E6%2596%25A9%25E8%258E%25B7%25E5%2585%25A8%25E9%2583%25A8%25E5%25A5%2596%25E9%25A1%25B9%25E5%259B%259B%25E6%2588%2590%25E4%25BD%259C%25E8%2580%2585%25E6%259D%25A5%25E8%2587%25AA%25E4%25B8%25AD%25E5%259B%25BD%25E6%25B8%2585%25E5%258D%258E%25E6%258E%2592%25E5%2590%258D%25E7%25AC%25AC%25E4%25B8%2580">脚步一旦踏错，便是另一番人生了丨人间日签</a></h2><p class=text-dark>人生的紧要处只有几步，
一旦走错了，就会像倒了的多米诺骨牌。
—— 齐文远
《世间又少了一个善良人》
点击查看原文
本文版权归属网易人间工作室所有，如需转载请在后台回复【转载】。
投稿给“人间-非虚构”写作平台，可致 …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/278833bb3b4130fc07d17f0c7dc6e5a4/?utm_source=see_also&utm_medium=%25E5%258D%258E%25E4%25BA%25BA%25E5%2588%25B6%25E9%259C%25B8cvpr%25E6%2596%25A9%25E8%258E%25B7%25E5%2585%25A8%25E9%2583%25A8%25E5%25A5%2596%25E9%25A1%25B9%25E5%259B%259B%25E6%2588%2590%25E4%25BD%259C%25E8%2580%2585%25E6%259D%25A5%25E8%2587%25AA%25E4%25B8%25AD%25E5%259B%25BD%25E6%25B8%2585%25E5%258D%258E%25E6%258E%2592%25E5%2590%258D%25E7%25AC%25AC%25E4%25B8%2580">生活总还是要继续的丨人间日签</a></h2><p class=text-dark>生活总还是要继续的。
—— 城南巡捕
《烈酒结下的安达兄弟，一生都不会散》
点击查看原文
本文版权归属网易人间工作室所有，如需转载请在后台回复【转载】。
投稿给“人间-非虚构”写作平台，可致信：thelivings@vip.163.com， …</p></article><article class=mb-5><h2 class=h5><a class=text-dark href="https://project-gutenberg.github.io/Pincong/post/29bc4792c96025d9673e20f098cdd6d7/?utm_source=see_also&utm_medium=%25E5%258D%258E%25E4%25BA%25BA%25E5%2588%25B6%25E9%259C%25B8cvpr%25E6%2596%25A9%25E8%258E%25B7%25E5%2585%25A8%25E9%2583%25A8%25E5%25A5%2596%25E9%25A1%25B9%25E5%259B%259B%25E6%2588%2590%25E4%25BD%259C%25E8%2580%2585%25E6%259D%25A5%25E8%2587%25AA%25E4%25B8%25AD%25E5%259B%25BD%25E6%25B8%2585%25E5%258D%258E%25E6%258E%2592%25E5%2590%258D%25E7%25AC%25AC%25E4%25B8%2580">保留一颗童真未失的心丨人间日签</a></h2><p class=text-dark>简单快乐，
终需要一颗童真未失的心。
—— 索文
《几十年前不懂的道理，都在一碗粉里》
点击查看原文
本文版权归属网易人间工作室所有，如需转载请在后台回复【转载】。
投稿给“人间-非虚构”写作平台，可致 …</p></article></div></div></div></div></div></div></div></div></section><script>var i,images=document.getElementsByTagName("img");for(i=0;i<images.length;i++)images[i].className+="img-fluid w-100 mb-4"</script><footer class="py-4 bg-light border-top"><div class=container><div class="row justify-content-between align-items-center"><div class="col-lg-4 text-center text-lg-left mb-4 mb-lg-0"><a href=https://project-gutenberg.github.io/Pincong/><img src=https://project-gutenberg.github.io/Pincong//images/logo.png class=img-fluid alt=品葱*精选></a></div><div class="col-lg-4 text-center mb-4 mb-lg-0"><ul class="list-inline mb-0"></ul></div><div class="col-lg-4 text-lg-right text-center mb-4 mb-lg-0"><ul class="list-inline social-icon mb-0"><li class=list-inline-item><a href=https://pincong.rocks/><i class=ti-home></i></a></li><li class=list-inline-item><a href=https://github.com/Project-Gutenberg/Pincong><i class=ti-github></i></a></li></ul></div><div class="col-12 text-center mt-4"><span></span></div></div></div></footer><script src=../../plugins/jQuery/jquery.min.js></script>
<script src=../../plugins/bootstrap/bootstrap.min.js></script>
<script src=../../plugins/search/fuse.min.js></script>
<script src=../../plugins/search/mark.js></script>
<script src=../../plugins/search/search.js></script>
<script src=https://project-gutenberg.github.io/Pincong/js/script.min.js></script>
<script>(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)})(window,document,'script','//www.google-analytics.com/analytics.js','ga'),ga('create','UA-151212685-6','auto'),ga('send','pageview')</script></body></html>